{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0.]\n",
      "8000\n",
      "2000\n",
      "[14. 15. 19. ...  8. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import utils\n",
    "import sys\n",
    "\n",
    "#Must Change if puzzle is a different size\n",
    "ROWS = 5\n",
    "COLUMNS = 5\n",
    "\n",
    "#Loads Training Data\n",
    "#data = np.loadtxt('../data/random_canon_SUSPs_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "data = np.loadtxt('../data/HeursticData.csv',dtype = float, delimiter = ',' )\n",
    "\n",
    "#Choose which heuristics to attempt to learn (Column 8 or 9)\n",
    "y = data[:,8]\n",
    "\n",
    "\n",
    "#Choosing which features to include in X data Remove other heuristics -- likely\n",
    "#X = data[:,8:-1]\n",
    "#print(data[0])\n",
    "\n",
    "X = data[:,10:-1] #Currently doesnt include Percent features\n",
    "print(X[0])\n",
    "\n",
    "\n",
    "#Creates a testing and training split that is stratified #Not stratified!\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nfrom scipy import stats\\n\\nfrom sklearn import model_selection\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.svm import SVC\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.dummy import DummyClassifier\\nfrom sklearn.feature_selection import RFE\\n\\n\\n# prepare configuration for cross validation test harness\\nseed = 1\\n\\n# prepare models\\nmodels = []\\nmodels.append((\\'ZR\\', DummyClassifier(strategy=\"most_frequent\")))\\nmodels.append((\\'LR\\', LogisticRegression(solver=\\'liblinear\\')))\\n#models.append((\\'KN5\\', KNeighborsClassifier()))  # Too Slow commented out\\n#models.append((\\'KN7\\', KNeighborsClassifier(n_neighbors=7)))\\nmodels.append((\\'DT\\', DecisionTreeClassifier()))\\nmodels.append((\\'NB\\', GaussianNB()))\\n#models.append((\\'SVM\\', SVC(gamma=\\'auto\\')))\\n#models.append((\\'LIN\\', SVC(kernel=\\'linear\\',gamma=\\'auto\\')))\\n#models.append((\\'RF\\',RandomForestClassifier(n_estimators=100)))\\n\\n# evaluate each model in turn\\n# note that I\\'m going to run through each model above\\n# performing a 10-fold cross-validation each time\\n# (n_splits = 10), specifying \\'accuracy\\' as my measure\\n\\nresults = []\\nclassifiers = []\\nscoring = \\'accuracy\\'\\nfor name, model in models:\\n\\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\\n\\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\\n\\tresults.append(cv_results)\\n\\tclassifiers.append(name)\\n\\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\\n\\tprint(msg)\\n\\n    \\n    \\n# boxplot algorithm comparison\\n\\nfig = plt.figure()\\nfig.suptitle(\\'Algorithm Comparison\\')\\nax = fig.add_subplot(111)\\nplt.boxplot(results)\\nax.set_xticklabels(classifiers)\\nplt.show()\\n\\n#print(\\'\\n***Performing t-tests***\\n\\n\\')\\n\\n    \\n#ttest,pval = stats.ttest_rel(results[0], results[1])\\n#print(\\'P-Val between ZeroR and Logistic Regression: %.2f\\' % pval)\\n\\n#if pval<0.05:\\n#    print(\"reject null hypothesis\")\\n#else:\\n#    print(\"accept null hypothesis\") \\n\\n#print()    \\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 1\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('ZR', DummyClassifier(strategy=\"most_frequent\")))\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "#models.append(('KN5', KNeighborsClassifier()))  # Too Slow commented out\n",
    "#models.append(('KN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC(gamma='auto')))\n",
    "#models.append(('LIN', SVC(kernel='linear',gamma='auto')))\n",
    "#models.append(('RF',RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "# note that I'm going to run through each model above\n",
    "# performing a 10-fold cross-validation each time\n",
    "# (n_splits = 10), specifying 'accuracy' as my measure\n",
    "\n",
    "results = []\n",
    "classifiers = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tclassifiers.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "    \n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(classifiers)\n",
    "plt.show()\n",
    "\n",
    "#print('\\n***Performing t-tests***\\n\\n')\n",
    "\n",
    "    \n",
    "#ttest,pval = stats.ttest_rel(results[0], results[1])\n",
    "#print('P-Val between ZeroR and Logistic Regression: %.2f' % pval)\n",
    "\n",
    "#if pval<0.05:\n",
    "#    print(\"reject null hypothesis\")\n",
    "#else:\n",
    "#    print(\"accept null hypothesis\") \n",
    "\n",
    "#print()    \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:  4.744851685313779\n"
     ]
    }
   ],
   "source": [
    "#Baseline Regression Model\n",
    "\n",
    "def mse_eval(actual, predicted):\n",
    "    sum = 0.0\n",
    "    for y in range(len(actual)):\n",
    "        sum += (predicted[y] - actual[y])**2\n",
    "    avg = sum/len(predicted)\n",
    "    return avg\n",
    "\n",
    "def zeroRR(train_y, test_y):\n",
    "    meanOfY = mean(train_y)\n",
    "    predicitions = [meanOfY for data in test_y]\n",
    "    return predicitions\n",
    "\n",
    "def mean(listOfValues):\n",
    "    sum = 0\n",
    "    for data in listOfValues:\n",
    "        sum += data\n",
    "    return sum/len(listOfValues)\n",
    "\n",
    "print(\"Baseline: \", rmse_eval(y_test, zeroRR(y_train, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Features:  75\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_237 (Dense)            (None, 98)                7448      \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 230,693\n",
      "Trainable params: 230,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 4s 606us/step - loss: 161.2368 - mean_squared_error: 161.2368 - val_loss: 165.7090 - val_mean_squared_error: 165.7090\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 1s 82us/step - loss: 67.3898 - mean_squared_error: 67.3898 - val_loss: 154.4456 - val_mean_squared_error: 154.4456\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 1s 84us/step - loss: 49.9506 - mean_squared_error: 49.9506 - val_loss: 140.8911 - val_mean_squared_error: 140.8911\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 1s 87us/step - loss: 43.5026 - mean_squared_error: 43.5026 - val_loss: 119.6023 - val_mean_squared_error: 119.6023\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 1s 87us/step - loss: 36.1524 - mean_squared_error: 36.1524 - val_loss: 92.8084 - val_mean_squared_error: 92.8084\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 1s 86us/step - loss: 33.3893 - mean_squared_error: 33.3893 - val_loss: 68.3099 - val_mean_squared_error: 68.3099\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 1s 83us/step - loss: 30.9949 - mean_squared_error: 30.9949 - val_loss: 60.6494 - val_mean_squared_error: 60.6494\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 1s 152us/step - loss: 29.9736 - mean_squared_error: 29.9736 - val_loss: 49.2485 - val_mean_squared_error: 49.2485\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 29.6280 - mean_squared_error: 29.6280 - val_loss: 47.3377 - val_mean_squared_error: 47.3377\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 1s 118us/step - loss: 28.9322 - mean_squared_error: 28.9322 - val_loss: 39.7911 - val_mean_squared_error: 39.7911\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 1s 87us/step - loss: 28.1645 - mean_squared_error: 28.1645 - val_loss: 37.4536 - val_mean_squared_error: 37.4536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 28.3149 - mean_squared_error: 28.3149 - val_loss: 35.6452 - val_mean_squared_error: 35.6452\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 27.9797 - mean_squared_error: 27.9797 - val_loss: 30.7839 - val_mean_squared_error: 30.7839\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 27.6233 - mean_squared_error: 27.6233 - val_loss: 29.7011 - val_mean_squared_error: 29.7011\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 27.2060 - mean_squared_error: 27.2060 - val_loss: 29.3242 - val_mean_squared_error: 29.3242\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 1s 82us/step - loss: 27.2338 - mean_squared_error: 27.2338 - val_loss: 32.7555 - val_mean_squared_error: 32.7555\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 27.1706 - mean_squared_error: 27.1706 - val_loss: 30.6691 - val_mean_squared_error: 30.6691\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 26.3303 - mean_squared_error: 26.3303 - val_loss: 31.2568 - val_mean_squared_error: 31.2568\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 26.1999 - mean_squared_error: 26.1999 - val_loss: 30.3184 - val_mean_squared_error: 30.3184\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 25.9597 - mean_squared_error: 25.9597 - val_loss: 31.2058 - val_mean_squared_error: 31.2058\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 25.5036 - mean_squared_error: 25.5036 - val_loss: 30.0296 - val_mean_squared_error: 30.0296\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 24.6280 - mean_squared_error: 24.6280 - val_loss: 31.8034 - val_mean_squared_error: 31.8034\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 24.1260 - mean_squared_error: 24.1260 - val_loss: 30.5976 - val_mean_squared_error: 30.5976\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 23.9959 - mean_squared_error: 23.9959 - val_loss: 29.5235 - val_mean_squared_error: 29.5235\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 23.9765 - mean_squared_error: 23.9765 - val_loss: 26.4539 - val_mean_squared_error: 26.4539\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 1s 82us/step - loss: 23.3177 - mean_squared_error: 23.3177 - val_loss: 26.3853 - val_mean_squared_error: 26.3853\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 23.1389 - mean_squared_error: 23.1389 - val_loss: 27.0317 - val_mean_squared_error: 27.0317\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 23.1048 - mean_squared_error: 23.1048 - val_loss: 27.4236 - val_mean_squared_error: 27.4236\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 22.6245 - mean_squared_error: 22.6245 - val_loss: 27.1322 - val_mean_squared_error: 27.1322\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 22.5954 - mean_squared_error: 22.5954 - val_loss: 26.6112 - val_mean_squared_error: 26.6112\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 22.6763 - mean_squared_error: 22.6763 - val_loss: 25.4561 - val_mean_squared_error: 25.4561\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 1s 83us/step - loss: 22.2835 - mean_squared_error: 22.2835 - val_loss: 29.6221 - val_mean_squared_error: 29.6221\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 22.4997 - mean_squared_error: 22.4997 - val_loss: 29.1750 - val_mean_squared_error: 29.1750\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 22.0811 - mean_squared_error: 22.0811 - val_loss: 26.8182 - val_mean_squared_error: 26.8182\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 21.3529 - mean_squared_error: 21.3529 - val_loss: 25.4877 - val_mean_squared_error: 25.4877\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 1s 78us/step - loss: 21.3289 - mean_squared_error: 21.3289 - val_loss: 27.0825 - val_mean_squared_error: 27.0825\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 20.6369 - mean_squared_error: 20.6369 - val_loss: 27.3547 - val_mean_squared_error: 27.3547\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 21.0729 - mean_squared_error: 21.0729 - val_loss: 26.6370 - val_mean_squared_error: 26.6370\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 20.7449 - mean_squared_error: 20.7449 - val_loss: 28.6260 - val_mean_squared_error: 28.6260\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 20.1449 - mean_squared_error: 20.1449 - val_loss: 25.4307 - val_mean_squared_error: 25.4307\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 1s 84us/step - loss: 19.6563 - mean_squared_error: 19.6563 - val_loss: 25.1281 - val_mean_squared_error: 25.1281\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 1s 83us/step - loss: 19.2719 - mean_squared_error: 19.2719 - val_loss: 24.8211 - val_mean_squared_error: 24.8211\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 19.3458 - mean_squared_error: 19.3458 - val_loss: 24.5566 - val_mean_squared_error: 24.5566\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 1s 85us/step - loss: 18.8168 - mean_squared_error: 18.8168 - val_loss: 21.1957 - val_mean_squared_error: 21.1957\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 1s 84us/step - loss: 18.8255 - mean_squared_error: 18.8255 - val_loss: 23.1331 - val_mean_squared_error: 23.1331\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 18.0271 - mean_squared_error: 18.0271 - val_loss: 21.7170 - val_mean_squared_error: 21.7170\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 17.7375 - mean_squared_error: 17.7375 - val_loss: 23.1252 - val_mean_squared_error: 23.1252\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 17.8003 - mean_squared_error: 17.8003 - val_loss: 23.6064 - val_mean_squared_error: 23.6064\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 17.7040 - mean_squared_error: 17.7040 - val_loss: 19.2581 - val_mean_squared_error: 19.2581\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 16.7346 - mean_squared_error: 16.7346 - val_loss: 19.9384 - val_mean_squared_error: 19.9384\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 78us/step - loss: 16.9901 - mean_squared_error: 16.9901 - val_loss: 22.2977 - val_mean_squared_error: 22.2977\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 16.7118 - mean_squared_error: 16.7118 - val_loss: 22.0854 - val_mean_squared_error: 22.0854\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 16.7095 - mean_squared_error: 16.7095 - val_loss: 22.5219 - val_mean_squared_error: 22.5219\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 16.3066 - mean_squared_error: 16.3066 - val_loss: 18.8619 - val_mean_squared_error: 18.8619\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 1s 83us/step - loss: 16.7730 - mean_squared_error: 16.7730 - val_loss: 19.6812 - val_mean_squared_error: 19.6812\n",
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 16.6883 - mean_squared_error: 16.6883 - val_loss: 23.2412 - val_mean_squared_error: 23.2412\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 16.4951 - mean_squared_error: 16.4951 - val_loss: 22.2262 - val_mean_squared_error: 22.2262\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 15.3837 - mean_squared_error: 15.3837 - val_loss: 21.3068 - val_mean_squared_error: 21.3068\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 1s 85us/step - loss: 15.0982 - mean_squared_error: 15.0982 - val_loss: 21.1202 - val_mean_squared_error: 21.1202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 15.0971 - mean_squared_error: 15.0971 - val_loss: 19.2814 - val_mean_squared_error: 19.2814\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 15.3219 - mean_squared_error: 15.3219 - val_loss: 21.0666 - val_mean_squared_error: 21.0666\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 72us/step - loss: 14.7463 - mean_squared_error: 14.7463 - val_loss: 20.7273 - val_mean_squared_error: 20.7273\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 15.0301 - mean_squared_error: 15.0301 - val_loss: 21.5551 - val_mean_squared_error: 21.5551\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 14.8024 - mean_squared_error: 14.8024 - val_loss: 20.3746 - val_mean_squared_error: 20.3746\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 14.6235 - mean_squared_error: 14.6235 - val_loss: 21.8143 - val_mean_squared_error: 21.8143\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 14.4544 - mean_squared_error: 14.4544 - val_loss: 20.5369 - val_mean_squared_error: 20.5369\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 14.0993 - mean_squared_error: 14.0993 - val_loss: 23.2046 - val_mean_squared_error: 23.2046\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 14.0626 - mean_squared_error: 14.0626 - val_loss: 24.0695 - val_mean_squared_error: 24.0695\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 13.9927 - mean_squared_error: 13.9927 - val_loss: 20.2590 - val_mean_squared_error: 20.2590\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 13.6852 - mean_squared_error: 13.6852 - val_loss: 22.9037 - val_mean_squared_error: 22.9037\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 13.6145 - mean_squared_error: 13.6145 - val_loss: 20.1827 - val_mean_squared_error: 20.1827\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 13.8876 - mean_squared_error: 13.8876 - val_loss: 23.4109 - val_mean_squared_error: 23.4109\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 13.8039 - mean_squared_error: 13.8039 - val_loss: 21.8812 - val_mean_squared_error: 21.8812\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 13.9008 - mean_squared_error: 13.9008 - val_loss: 21.4402 - val_mean_squared_error: 21.4402\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 13.5412 - mean_squared_error: 13.5412 - val_loss: 20.1373 - val_mean_squared_error: 20.1373\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 13.7360 - mean_squared_error: 13.7360 - val_loss: 22.1091 - val_mean_squared_error: 22.1091\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 14.2033 - mean_squared_error: 14.2033 - val_loss: 21.0324 - val_mean_squared_error: 21.0324\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 13.7654 - mean_squared_error: 13.7654 - val_loss: 21.3400 - val_mean_squared_error: 21.3400\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 1s 82us/step - loss: 13.5435 - mean_squared_error: 13.5435 - val_loss: 17.9326 - val_mean_squared_error: 17.9326\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 1s 83us/step - loss: 13.1764 - mean_squared_error: 13.1764 - val_loss: 19.8684 - val_mean_squared_error: 19.8684\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 13.3685 - mean_squared_error: 13.3685 - val_loss: 19.7928 - val_mean_squared_error: 19.7928\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 13.1327 - mean_squared_error: 13.1327 - val_loss: 20.6246 - val_mean_squared_error: 20.6246\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.8519 - mean_squared_error: 12.8519 - val_loss: 20.8089 - val_mean_squared_error: 20.8089\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.9544 - mean_squared_error: 12.9544 - val_loss: 19.8688 - val_mean_squared_error: 19.8688\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.5126 - mean_squared_error: 12.5126 - val_loss: 20.4599 - val_mean_squared_error: 20.4599\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 12.8036 - mean_squared_error: 12.8036 - val_loss: 19.8401 - val_mean_squared_error: 19.8401\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.7571 - mean_squared_error: 12.7571 - val_loss: 20.1619 - val_mean_squared_error: 20.1619\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 13.1151 - mean_squared_error: 13.1151 - val_loss: 20.1555 - val_mean_squared_error: 20.1555\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.4867 - mean_squared_error: 12.4867 - val_loss: 22.1738 - val_mean_squared_error: 22.1738\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.6536 - mean_squared_error: 12.6536 - val_loss: 18.7342 - val_mean_squared_error: 18.7342\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.6377 - mean_squared_error: 12.6377 - val_loss: 21.6779 - val_mean_squared_error: 21.6779\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.4220 - mean_squared_error: 12.4220 - val_loss: 21.9577 - val_mean_squared_error: 21.9577\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.0344 - mean_squared_error: 12.0344 - val_loss: 22.4354 - val_mean_squared_error: 22.4354\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.9145 - mean_squared_error: 11.9145 - val_loss: 21.1738 - val_mean_squared_error: 21.1738\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.0327 - mean_squared_error: 12.0327 - val_loss: 20.4642 - val_mean_squared_error: 20.4642\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.3171 - mean_squared_error: 12.3171 - val_loss: 20.5687 - val_mean_squared_error: 20.5687\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.9603 - mean_squared_error: 11.9603 - val_loss: 19.2270 - val_mean_squared_error: 19.2270\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 12.6657 - mean_squared_error: 12.6657 - val_loss: 22.9210 - val_mean_squared_error: 22.9210\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.8455 - mean_squared_error: 11.8455 - val_loss: 21.1805 - val_mean_squared_error: 21.1805\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.1125 - mean_squared_error: 12.1125 - val_loss: 21.8786 - val_mean_squared_error: 21.8786\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 11.7648 - mean_squared_error: 11.7648 - val_loss: 20.9607 - val_mean_squared_error: 20.9607\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.4550 - mean_squared_error: 12.4550 - val_loss: 21.1724 - val_mean_squared_error: 21.1724\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.9777 - mean_squared_error: 11.9777 - val_loss: 18.3428 - val_mean_squared_error: 18.3428\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 12.0760 - mean_squared_error: 12.0760 - val_loss: 18.5893 - val_mean_squared_error: 18.5893\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.8230 - mean_squared_error: 11.8230 - val_loss: 19.7376 - val_mean_squared_error: 19.7376\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.8015 - mean_squared_error: 11.8015 - val_loss: 20.3101 - val_mean_squared_error: 20.3101\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.4163 - mean_squared_error: 11.4163 - val_loss: 22.0271 - val_mean_squared_error: 22.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.3749 - mean_squared_error: 11.3749 - val_loss: 20.6885 - val_mean_squared_error: 20.6885\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 72us/step - loss: 11.2202 - mean_squared_error: 11.2202 - val_loss: 19.4317 - val_mean_squared_error: 19.4317\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 72us/step - loss: 10.9317 - mean_squared_error: 10.9317 - val_loss: 19.6719 - val_mean_squared_error: 19.6719\n",
      "Epoch 111/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.2890 - mean_squared_error: 11.2890 - val_loss: 22.8497 - val_mean_squared_error: 22.8497\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 77us/step - loss: 11.0397 - mean_squared_error: 11.0397 - val_loss: 20.9734 - val_mean_squared_error: 20.9734\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.9474 - mean_squared_error: 10.9474 - val_loss: 19.0669 - val_mean_squared_error: 19.0669\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.1357 - mean_squared_error: 11.1357 - val_loss: 19.7281 - val_mean_squared_error: 19.7281\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.5663 - mean_squared_error: 11.5663 - val_loss: 21.0802 - val_mean_squared_error: 21.0802\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.0660 - mean_squared_error: 11.0660 - val_loss: 21.2795 - val_mean_squared_error: 21.2795\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.5501 - mean_squared_error: 11.5501 - val_loss: 23.2968 - val_mean_squared_error: 23.2968\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 12.2019 - mean_squared_error: 12.2019 - val_loss: 19.6298 - val_mean_squared_error: 19.6298\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 12.5604 - mean_squared_error: 12.5604 - val_loss: 21.0561 - val_mean_squared_error: 21.0561\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 12.3052 - mean_squared_error: 12.3052 - val_loss: 20.5712 - val_mean_squared_error: 20.5712\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.7836 - mean_squared_error: 11.7836 - val_loss: 20.2604 - val_mean_squared_error: 20.2604\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.6981 - mean_squared_error: 11.6981 - val_loss: 19.2474 - val_mean_squared_error: 19.2474\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.3118 - mean_squared_error: 11.3118 - val_loss: 21.9450 - val_mean_squared_error: 21.9450\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.5913 - mean_squared_error: 11.5913 - val_loss: 20.2998 - val_mean_squared_error: 20.2998\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 72us/step - loss: 10.7043 - mean_squared_error: 10.7043 - val_loss: 19.7024 - val_mean_squared_error: 19.7024\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.0348 - mean_squared_error: 11.0348 - val_loss: 19.3816 - val_mean_squared_error: 19.3816\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.3982 - mean_squared_error: 11.3982 - val_loss: 17.6713 - val_mean_squared_error: 17.6713\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 11.9756 - mean_squared_error: 11.9756 - val_loss: 20.4462 - val_mean_squared_error: 20.4462\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.0909 - mean_squared_error: 11.0909 - val_loss: 19.3605 - val_mean_squared_error: 19.3605\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.0598 - mean_squared_error: 11.0598 - val_loss: 20.2798 - val_mean_squared_error: 20.2798\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.8080 - mean_squared_error: 10.8080 - val_loss: 21.1637 - val_mean_squared_error: 21.1637\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 11.0328 - mean_squared_error: 11.0328 - val_loss: 21.6645 - val_mean_squared_error: 21.6645\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 10.6936 - mean_squared_error: 10.6936 - val_loss: 19.7413 - val_mean_squared_error: 19.7413\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 11.3491 - mean_squared_error: 11.3491 - val_loss: 19.8753 - val_mean_squared_error: 19.8753\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.8989 - mean_squared_error: 10.8989 - val_loss: 20.7677 - val_mean_squared_error: 20.7677\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.3708 - mean_squared_error: 10.3708 - val_loss: 19.9339 - val_mean_squared_error: 19.9339\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.3773 - mean_squared_error: 10.3773 - val_loss: 18.8249 - val_mean_squared_error: 18.8249\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.3566 - mean_squared_error: 10.3566 - val_loss: 18.9380 - val_mean_squared_error: 18.9380\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.4938 - mean_squared_error: 10.4938 - val_loss: 20.1170 - val_mean_squared_error: 20.1170\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 10.6476 - mean_squared_error: 10.6476 - val_loss: 20.4930 - val_mean_squared_error: 20.4930\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 11.3024 - mean_squared_error: 11.3024 - val_loss: 19.2651 - val_mean_squared_error: 19.2651\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 11.0220 - mean_squared_error: 11.0220 - val_loss: 20.5160 - val_mean_squared_error: 20.5160\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.5983 - mean_squared_error: 10.5983 - val_loss: 20.0168 - val_mean_squared_error: 20.0168\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.4340 - mean_squared_error: 10.4340 - val_loss: 19.9289 - val_mean_squared_error: 19.9289\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.4974 - mean_squared_error: 10.4974 - val_loss: 21.3886 - val_mean_squared_error: 21.3886\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 9.8855 - mean_squared_error: 9.8855 - val_loss: 20.2324 - val_mean_squared_error: 20.2324\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.1068 - mean_squared_error: 10.1068 - val_loss: 20.8251 - val_mean_squared_error: 20.8251\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 9.6242 - mean_squared_error: 9.6242 - val_loss: 19.6240 - val_mean_squared_error: 19.6240\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.1523 - mean_squared_error: 10.1523 - val_loss: 20.5725 - val_mean_squared_error: 20.5725\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.9363 - mean_squared_error: 9.9363 - val_loss: 18.8012 - val_mean_squared_error: 18.8012\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.4905 - mean_squared_error: 10.4905 - val_loss: 20.8201 - val_mean_squared_error: 20.8201\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.8748 - mean_squared_error: 10.8748 - val_loss: 20.0386 - val_mean_squared_error: 20.0386\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 10.4489 - mean_squared_error: 10.4489 - val_loss: 20.9628 - val_mean_squared_error: 20.9628\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 10.4897 - mean_squared_error: 10.4897 - val_loss: 20.3141 - val_mean_squared_error: 20.3141\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 10.1237 - mean_squared_error: 10.1237 - val_loss: 20.6751 - val_mean_squared_error: 20.6751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.9973 - mean_squared_error: 9.9973 - val_loss: 20.8160 - val_mean_squared_error: 20.8160\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.8870 - mean_squared_error: 9.8870 - val_loss: 22.0661 - val_mean_squared_error: 22.0661\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 9.7443 - mean_squared_error: 9.7443 - val_loss: 21.4680 - val_mean_squared_error: 21.4680\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.5614 - mean_squared_error: 9.5614 - val_loss: 20.3293 - val_mean_squared_error: 20.3293\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.3190 - mean_squared_error: 9.3190 - val_loss: 18.4874 - val_mean_squared_error: 18.4874\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.6120 - mean_squared_error: 9.6120 - val_loss: 19.1484 - val_mean_squared_error: 19.1484\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.5521 - mean_squared_error: 9.5521 - val_loss: 19.0162 - val_mean_squared_error: 19.0162\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.6005 - mean_squared_error: 9.6005 - val_loss: 20.9578 - val_mean_squared_error: 20.9578\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 9.4608 - mean_squared_error: 9.4608 - val_loss: 19.1016 - val_mean_squared_error: 19.1016\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.0670 - mean_squared_error: 9.0670 - val_loss: 21.7374 - val_mean_squared_error: 21.7374\n",
      "Epoch 166/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.9848 - mean_squared_error: 9.9848 - val_loss: 20.6133 - val_mean_squared_error: 20.6133\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.4512 - mean_squared_error: 9.4512 - val_loss: 20.0488 - val_mean_squared_error: 20.0488\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.3246 - mean_squared_error: 9.3246 - val_loss: 19.3857 - val_mean_squared_error: 19.3857\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.5031 - mean_squared_error: 9.5031 - val_loss: 20.6054 - val_mean_squared_error: 20.6054\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.2565 - mean_squared_error: 9.2565 - val_loss: 20.9298 - val_mean_squared_error: 20.9298\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.0734 - mean_squared_error: 9.0734 - val_loss: 19.9668 - val_mean_squared_error: 19.9668\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.3847 - mean_squared_error: 9.3847 - val_loss: 19.0845 - val_mean_squared_error: 19.0845\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.5059 - mean_squared_error: 9.5059 - val_loss: 20.0545 - val_mean_squared_error: 20.0545\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.1651 - mean_squared_error: 9.1651 - val_loss: 20.5955 - val_mean_squared_error: 20.5955\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.3598 - mean_squared_error: 9.3598 - val_loss: 19.2333 - val_mean_squared_error: 19.2333\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.4865 - mean_squared_error: 9.4865 - val_loss: 21.8393 - val_mean_squared_error: 21.8393\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 9.2155 - mean_squared_error: 9.2155 - val_loss: 20.6132 - val_mean_squared_error: 20.6132\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.6127 - mean_squared_error: 9.6127 - val_loss: 22.3364 - val_mean_squared_error: 22.3364\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.2323 - mean_squared_error: 9.2323 - val_loss: 20.4002 - val_mean_squared_error: 20.4002\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.1918 - mean_squared_error: 9.1918 - val_loss: 21.2496 - val_mean_squared_error: 21.2496\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 76us/step - loss: 9.1641 - mean_squared_error: 9.1641 - val_loss: 19.8508 - val_mean_squared_error: 19.8508\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 8.9021 - mean_squared_error: 8.9021 - val_loss: 19.3651 - val_mean_squared_error: 19.3651\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 8.9286 - mean_squared_error: 8.9286 - val_loss: 20.3429 - val_mean_squared_error: 20.3429\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 9.3547 - mean_squared_error: 9.3547 - val_loss: 21.0047 - val_mean_squared_error: 21.0047\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 8.8985 - mean_squared_error: 8.8985 - val_loss: 20.7704 - val_mean_squared_error: 20.7704\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.8248 - mean_squared_error: 8.8248 - val_loss: 20.9981 - val_mean_squared_error: 20.9981\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 8.4461 - mean_squared_error: 8.4461 - val_loss: 20.0915 - val_mean_squared_error: 20.0915\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.4080 - mean_squared_error: 8.4080 - val_loss: 19.9522 - val_mean_squared_error: 19.9522\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 8.7030 - mean_squared_error: 8.7030 - val_loss: 20.4727 - val_mean_squared_error: 20.4727\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.9164 - mean_squared_error: 8.9164 - val_loss: 20.4544 - val_mean_squared_error: 20.4544\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 8.7519 - mean_squared_error: 8.7519 - val_loss: 18.9067 - val_mean_squared_error: 18.9067\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.6790 - mean_squared_error: 8.6790 - val_loss: 19.9774 - val_mean_squared_error: 19.9774\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.4099 - mean_squared_error: 8.4099 - val_loss: 19.6888 - val_mean_squared_error: 19.6888\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 73us/step - loss: 8.6146 - mean_squared_error: 8.6146 - val_loss: 19.9623 - val_mean_squared_error: 19.9623\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.8635 - mean_squared_error: 8.8635 - val_loss: 18.4005 - val_mean_squared_error: 18.4005\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 9.0310 - mean_squared_error: 9.0310 - val_loss: 19.6544 - val_mean_squared_error: 19.6544\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 8.5661 - mean_squared_error: 8.5661 - val_loss: 19.4549 - val_mean_squared_error: 19.4549\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 1s 78us/step - loss: 8.6637 - mean_squared_error: 8.6637 - val_loss: 19.8950 - val_mean_squared_error: 19.8950\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 9.0646 - mean_squared_error: 9.0646 - val_loss: 20.7759 - val_mean_squared_error: 20.7759\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 75us/step - loss: 8.5958 - mean_squared_error: 8.5958 - val_loss: 21.0874 - val_mean_squared_error: 21.0874\n",
      "\n",
      "--- Learning curve of model training ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check against test data ---\n",
      "\n",
      "2000/2000 [==============================] - 0s 76us/step\n",
      "\n",
      "Mean Squared Error on test data: 22.28\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "numFeatures = len(X[0])\n",
    "print(\"Num of Features: \", numFeatures)\n",
    "\n",
    "\n",
    "DropoutAmount = 0.3\n",
    "NodesPerLayer= int((DropoutAmount*numFeatures)) + numFeatures + 1\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(1, activation='linear', kernel_initializer='normal'))\n",
    "print(model_m.summary())\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    #keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=3) #Is Val Loss correct?\n",
    "]\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model_m.compile(loss='mean_squared_error',\n",
    "                optimizer=opt, metrics=['mean_squared_error'])\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "EPOCHS = 200\n",
    "\n",
    "history = model_m.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)\n",
    "\n",
    "print(\"\\n--- Learning curve of model training ---\\n\")\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['mean_squared_error'], \"g--\", label=\"MSE of training data\")\n",
    "plt.plot(history.history['val_mean_squared_error'], \"g\", label=\"MSE of validation data\")\n",
    "plt.title('Model MSE and Loss')\n",
    "plt.ylabel('MSE and Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Check against test data ---\\n\")\n",
    "\n",
    "\n",
    "#8 by 5, 9 by 5\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(\"\\nMean Squared Error on test data: %0.2f\" % score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 102)               8058      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 206       \n",
      "=================================================================\n",
      "Total params: 60,794\n",
      "Trainable params: 60,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "50000/50000 [==============================] - 2s 30us/step\n",
      "True Positives:  11018\n",
      "True Negatives:  30497\n",
      "False Positives:  6630\n",
      "False Negatives:  1855\n",
      "\n",
      "Recall: 0.856\n",
      "Precision: 0.624\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d56246bc44fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on test data: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLoss on test data: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "modelName = \"best_model.52-0.31.h5\"\n",
    "\n",
    "#data =  np.loadtxt('../data/random_c_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#names = data[0]\n",
    "#data = data[1:]\n",
    "\n",
    "#Sets class data to y\n",
    "#y = data[:,-1]\n",
    "\n",
    "#Choosing which features to include in X data Must be same as trained above\n",
    "#X = data[:,5:-1]\n",
    "\n",
    "#y = keras.utils.to_categorical(y) \n",
    "\n",
    "\n",
    "\n",
    "model = load_model(modelName)\n",
    "model.summary()\n",
    "\n",
    "first = time.time()\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total = end - first\n",
    "\n",
    "y_pred = model_m.predict(x_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)).ravel()\n",
    "\n",
    "print(\"True Positives: \", tp)\n",
    "print(\"True Negatives: \", tn)\n",
    "print(\"False Positives: \", fp)\n",
    "print(\"False Negatives: \", fn)\n",
    "\n",
    "\n",
    "suspNum = 0\n",
    "\n",
    "for instance in y_test:\n",
    "    if instance[1] == 1:\n",
    "        suspNum += 1\n",
    "\n",
    "print(\"\\nRecall: %0.3f\" % (tp/(tp+fn)))\n",
    "print(\"Precision: %0.3f\" % (tp/(tp+fp)))\n",
    "\n",
    "print(\"Accuracy on test data: %0.3f\" % (tp+tn)/len(y_test))\n",
    "print(\"\\nLoss on test data: %0.3f\" % score[0])\n",
    "\n",
    "print(\"Total Time: \", total)\n",
    "print(\"Time Per: \", total/len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
