{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2133e+04 2.3321e+04 3.2133e+04 2.3333e+04 4.4000e-01 3.2000e-01\n",
      " 2.4000e-01 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[0.44 0.32 0.24 0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.\n",
      " 1.   0.   1.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.\n",
      " 0.   1.   1.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      " 1.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.   1.   0.   0.\n",
      " 0.   1.   0.   0.   0.   1.   0.   0.   0.   1.   1.   0.   0.   1.\n",
      " 0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.\n",
      " 1.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "400000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import utils\n",
    "import sys\n",
    "\n",
    "\n",
    "#Loads Training Data\n",
    "data =  np.loadtxt('../data/random_canon_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#names = data[0]\n",
    "#data = data[1:]\n",
    "\n",
    "\n",
    "#Loads Extra SUSP data to increase class percentage\n",
    "extraSUSPs = np.loadtxt('../data/random_canon_SUSPs_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#extraSUSPs = extraSUSPs[1:]\n",
    "\n",
    "data45 =  np.loadtxt('../data/random_canon_r4_c5.csv',dtype = float, delimiter = ',')\n",
    "extraSUSPs45 = np.loadtxt('../data/random_canon_SUSPs_r4_c5.csv',dtype = float, delimiter = ',')\n",
    "\n",
    "\n",
    "#Creates one dataset\n",
    "data = np.concatenate([data, extraSUSPs])\n",
    "data45 = np.concatenate([data45, extraSUSPs45])\n",
    "\n",
    "data = data[:,1:]\n",
    "\n",
    "data = np.concatenate([data, data45])\n",
    "\n",
    "#Sets class data to y\n",
    "y = data[:,-1]\n",
    "\n",
    "#Choosing which features to include in X data\n",
    "#X = data[:,8:-1]\n",
    "print(data[0])\n",
    "\n",
    "X = data[:,4:-1]\n",
    "\n",
    "\n",
    "#X = X.astype(np.float)\n",
    "y = utils.to_categorical(y) #Done to make categorical loss functions work\n",
    "print(y)\n",
    "\n",
    "print(X[0])\n",
    "\n",
    "#le = preprocessing.LabelEncoder()\n",
    "\n",
    "#for i in range(ROWS+COLUMNS):\n",
    "#    X[:,i] = le.fit_transform(X[:,i])\n",
    "\n",
    "#cat_features = [0, 1, 2, 3 ,4 ,5 ,6 ,7 ,8 ,9]\n",
    "#enc = preprocessing.OneHotEncoder(categorical_features=cat_features)\n",
    "#enc.fit(X)\n",
    "\n",
    "#print(enc.n_values_)\n",
    "#print(enc.feature_indices_)\n",
    "#X = enc.transform(X).toarray()\n",
    "#print(X[0])\n",
    "\n",
    "\n",
    "#Creates a testing and training split that is stratified\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nfrom scipy import stats\\n\\nfrom sklearn import model_selection\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.svm import SVC\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.dummy import DummyClassifier\\nfrom sklearn.feature_selection import RFE\\n\\n\\n# prepare configuration for cross validation test harness\\nseed = 1\\n\\n# prepare models\\nmodels = []\\nmodels.append((\\'ZR\\', DummyClassifier(strategy=\"most_frequent\")))\\nmodels.append((\\'LR\\', LogisticRegression(solver=\\'liblinear\\')))\\n#models.append((\\'KN5\\', KNeighborsClassifier()))  # Too Slow commented out\\n#models.append((\\'KN7\\', KNeighborsClassifier(n_neighbors=7)))\\nmodels.append((\\'DT\\', DecisionTreeClassifier()))\\nmodels.append((\\'NB\\', GaussianNB()))\\n#models.append((\\'SVM\\', SVC(gamma=\\'auto\\')))\\n#models.append((\\'LIN\\', SVC(kernel=\\'linear\\',gamma=\\'auto\\')))\\n#models.append((\\'RF\\',RandomForestClassifier(n_estimators=100)))\\n\\n# evaluate each model in turn\\n# note that I\\'m going to run through each model above\\n# performing a 10-fold cross-validation each time\\n# (n_splits = 10), specifying \\'accuracy\\' as my measure\\n\\nresults = []\\nclassifiers = []\\nscoring = \\'accuracy\\'\\nfor name, model in models:\\n\\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\\n\\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\\n\\tresults.append(cv_results)\\n\\tclassifiers.append(name)\\n\\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\\n\\tprint(msg)\\n\\n    \\n    \\n# boxplot algorithm comparison\\n\\nfig = plt.figure()\\nfig.suptitle(\\'Algorithm Comparison\\')\\nax = fig.add_subplot(111)\\nplt.boxplot(results)\\nax.set_xticklabels(classifiers)\\nplt.show()\\n\\n#print(\\'\\n***Performing t-tests***\\n\\n\\')\\n\\n    \\n#ttest,pval = stats.ttest_rel(results[0], results[1])\\n#print(\\'P-Val between ZeroR and Logistic Regression: %.2f\\' % pval)\\n\\n#if pval<0.05:\\n#    print(\"reject null hypothesis\")\\n#else:\\n#    print(\"accept null hypothesis\") \\n\\n#print()    \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 1\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('ZR', DummyClassifier(strategy=\"most_frequent\")))\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "#models.append(('KN5', KNeighborsClassifier()))  # Too Slow commented out\n",
    "#models.append(('KN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC(gamma='auto')))\n",
    "#models.append(('LIN', SVC(kernel='linear',gamma='auto')))\n",
    "#models.append(('RF',RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "# note that I'm going to run through each model above\n",
    "# performing a 10-fold cross-validation each time\n",
    "# (n_splits = 10), specifying 'accuracy' as my measure\n",
    "\n",
    "results = []\n",
    "classifiers = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tclassifiers.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "    \n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(classifiers)\n",
    "plt.show()\n",
    "\n",
    "#print('\\n***Performing t-tests***\\n\\n')\n",
    "\n",
    "    \n",
    "#ttest,pval = stats.ttest_rel(results[0], results[1])\n",
    "#print('P-Val between ZeroR and Logistic Regression: %.2f' % pval)\n",
    "\n",
    "#if pval<0.05:\n",
    "#    print(\"reject null hypothesis\")\n",
    "#else:\n",
    "#    print(\"accept null hypothesis\") \n",
    "\n",
    "#print()    \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Features:  147\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 192)               28416     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 214,082\n",
      "Trainable params: 214,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 320000 samples, validate on 80000 samples\n",
      "Epoch 1/200\n",
      "320000/320000 [==============================] - 13s 39us/step - loss: 0.4979 - acc: 0.7300 - val_loss: 0.4270 - val_acc: 0.7716\n",
      "Epoch 2/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.4076 - acc: 0.7847 - val_loss: 0.3746 - val_acc: 0.8054\n",
      "Epoch 3/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.3681 - acc: 0.8081 - val_loss: 0.3512 - val_acc: 0.8170\n",
      "Epoch 4/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.3442 - acc: 0.8231 - val_loss: 0.3336 - val_acc: 0.8282\n",
      "Epoch 5/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.3291 - acc: 0.8333 - val_loss: 0.3261 - val_acc: 0.8357\n",
      "Epoch 6/200\n",
      "320000/320000 [==============================] - 25s 79us/step - loss: 0.3177 - acc: 0.8403 - val_loss: 0.3117 - val_acc: 0.8427\n",
      "Epoch 7/200\n",
      "320000/320000 [==============================] - 18s 56us/step - loss: 0.3083 - acc: 0.8456 - val_loss: 0.3087 - val_acc: 0.8430\n",
      "Epoch 8/200\n",
      "320000/320000 [==============================] - 20s 61us/step - loss: 0.3010 - acc: 0.8500 - val_loss: 0.3011 - val_acc: 0.8494\n",
      "Epoch 9/200\n",
      "320000/320000 [==============================] - 24s 75us/step - loss: 0.2947 - acc: 0.8542 - val_loss: 0.2941 - val_acc: 0.8541\n",
      "Epoch 10/200\n",
      "320000/320000 [==============================] - 13s 40us/step - loss: 0.2892 - acc: 0.8585 - val_loss: 0.2911 - val_acc: 0.8569\n",
      "Epoch 11/200\n",
      "320000/320000 [==============================] - 13s 40us/step - loss: 0.2831 - acc: 0.8612 - val_loss: 0.2883 - val_acc: 0.8587\n",
      "Epoch 12/200\n",
      "320000/320000 [==============================] - 20s 63us/step - loss: 0.2787 - acc: 0.8635 - val_loss: 0.2874 - val_acc: 0.8565\n",
      "Epoch 13/200\n",
      "320000/320000 [==============================] - 14s 42us/step - loss: 0.2749 - acc: 0.8670 - val_loss: 0.2807 - val_acc: 0.8628\n",
      "Epoch 14/200\n",
      "320000/320000 [==============================] - 18s 56us/step - loss: 0.2705 - acc: 0.8689 - val_loss: 0.2792 - val_acc: 0.8639\n",
      "Epoch 15/200\n",
      "320000/320000 [==============================] - 14s 45us/step - loss: 0.2678 - acc: 0.8706 - val_loss: 0.2785 - val_acc: 0.8645\n",
      "Epoch 16/200\n",
      "320000/320000 [==============================] - 12s 39us/step - loss: 0.2650 - acc: 0.8734 - val_loss: 0.2722 - val_acc: 0.8678\n",
      "Epoch 17/200\n",
      "320000/320000 [==============================] - 16s 50us/step - loss: 0.2608 - acc: 0.8749 - val_loss: 0.2734 - val_acc: 0.8677\n",
      "Epoch 18/200\n",
      "320000/320000 [==============================] - 15s 47us/step - loss: 0.2577 - acc: 0.8776 - val_loss: 0.2700 - val_acc: 0.8693\n",
      "Epoch 19/200\n",
      "320000/320000 [==============================] - 12s 39us/step - loss: 0.2552 - acc: 0.8786 - val_loss: 0.2635 - val_acc: 0.8718\n",
      "Epoch 20/200\n",
      "320000/320000 [==============================] - 16s 49us/step - loss: 0.2533 - acc: 0.8799 - val_loss: 0.2671 - val_acc: 0.8725\n",
      "Epoch 21/200\n",
      "320000/320000 [==============================] - 16s 49us/step - loss: 0.2503 - acc: 0.8813 - val_loss: 0.2632 - val_acc: 0.8741\n",
      "Epoch 22/200\n",
      "320000/320000 [==============================] - 13s 40us/step - loss: 0.2481 - acc: 0.8831 - val_loss: 0.2662 - val_acc: 0.8727\n",
      "Epoch 23/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2458 - acc: 0.8842 - val_loss: 0.2652 - val_acc: 0.8736\n",
      "Epoch 24/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2434 - acc: 0.8863 - val_loss: 0.2624 - val_acc: 0.8735\n",
      "Epoch 25/200\n",
      "320000/320000 [==============================] - 16s 49us/step - loss: 0.2424 - acc: 0.8868 - val_loss: 0.2580 - val_acc: 0.8756\n",
      "Epoch 26/200\n",
      "320000/320000 [==============================] - 20s 62us/step - loss: 0.2403 - acc: 0.8881 - val_loss: 0.2579 - val_acc: 0.8764\n",
      "Epoch 27/200\n",
      "320000/320000 [==============================] - 14s 43us/step - loss: 0.2376 - acc: 0.8893 - val_loss: 0.2583 - val_acc: 0.8768\n",
      "Epoch 28/200\n",
      "320000/320000 [==============================] - 14s 42us/step - loss: 0.2369 - acc: 0.8898 - val_loss: 0.2576 - val_acc: 0.8772\n",
      "Epoch 29/200\n",
      "320000/320000 [==============================] - 20s 63us/step - loss: 0.2350 - acc: 0.8908 - val_loss: 0.2566 - val_acc: 0.8785\n",
      "Epoch 30/200\n",
      "320000/320000 [==============================] - 12s 39us/step - loss: 0.2331 - acc: 0.8922 - val_loss: 0.2553 - val_acc: 0.8782\n",
      "Epoch 31/200\n",
      "320000/320000 [==============================] - 13s 41us/step - loss: 0.2318 - acc: 0.8929 - val_loss: 0.2566 - val_acc: 0.8788\n",
      "Epoch 32/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2305 - acc: 0.8936 - val_loss: 0.2589 - val_acc: 0.8770\n",
      "Epoch 33/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2298 - acc: 0.8942 - val_loss: 0.2528 - val_acc: 0.8807\n",
      "Epoch 34/200\n",
      "320000/320000 [==============================] - 16s 52us/step - loss: 0.2279 - acc: 0.8951 - val_loss: 0.2574 - val_acc: 0.8781\n",
      "Epoch 35/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2268 - acc: 0.8960 - val_loss: 0.2513 - val_acc: 0.8804\n",
      "Epoch 36/200\n",
      "320000/320000 [==============================] - 13s 40us/step - loss: 0.2258 - acc: 0.8965 - val_loss: 0.2512 - val_acc: 0.8813\n",
      "Epoch 37/200\n",
      "320000/320000 [==============================] - 12s 39us/step - loss: 0.2244 - acc: 0.8975 - val_loss: 0.2509 - val_acc: 0.8818\n",
      "Epoch 38/200\n",
      "320000/320000 [==============================] - 14s 43us/step - loss: 0.2221 - acc: 0.8985 - val_loss: 0.2548 - val_acc: 0.8806\n",
      "Epoch 39/200\n",
      "320000/320000 [==============================] - 14s 43us/step - loss: 0.2209 - acc: 0.8994 - val_loss: 0.2527 - val_acc: 0.8821\n",
      "Epoch 40/200\n",
      "320000/320000 [==============================] - 13s 39us/step - loss: 0.2202 - acc: 0.9000 - val_loss: 0.2515 - val_acc: 0.8812\n",
      "Epoch 41/200\n",
      "320000/320000 [==============================] - 13s 39us/step - loss: 0.2203 - acc: 0.8999 - val_loss: 0.2520 - val_acc: 0.8811\n",
      "Epoch 42/200\n",
      "320000/320000 [==============================] - 13s 40us/step - loss: 0.2198 - acc: 0.9004 - val_loss: 0.2509 - val_acc: 0.8827\n",
      "Epoch 43/200\n",
      "320000/320000 [==============================] - 11s 35us/step - loss: 0.2187 - acc: 0.9007 - val_loss: 0.2512 - val_acc: 0.8820\n",
      "Epoch 44/200\n",
      "320000/320000 [==============================] - 11s 36us/step - loss: 0.2178 - acc: 0.9018 - val_loss: 0.2489 - val_acc: 0.8843\n",
      "Epoch 45/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2162 - acc: 0.9022 - val_loss: 0.2496 - val_acc: 0.8831\n",
      "Epoch 46/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2157 - acc: 0.9022 - val_loss: 0.2517 - val_acc: 0.8820\n",
      "Epoch 47/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2146 - acc: 0.9030 - val_loss: 0.2499 - val_acc: 0.8835\n",
      "Epoch 48/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2130 - acc: 0.9038 - val_loss: 0.2496 - val_acc: 0.8821\n",
      "Epoch 49/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2129 - acc: 0.9044 - val_loss: 0.2498 - val_acc: 0.8820\n",
      "Epoch 50/200\n",
      "320000/320000 [==============================] - 12s 38us/step - loss: 0.2124 - acc: 0.9044 - val_loss: 0.2486 - val_acc: 0.8841\n",
      "Epoch 51/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2121 - acc: 0.9047 - val_loss: 0.2491 - val_acc: 0.8848\n",
      "Epoch 52/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2128 - acc: 0.9045 - val_loss: 0.2517 - val_acc: 0.8834\n",
      "Epoch 53/200\n",
      "320000/320000 [==============================] - 12s 37us/step - loss: 0.2108 - acc: 0.9054 - val_loss: 0.2500 - val_acc: 0.8830\n",
      "Epoch 54/200\n",
      "320000/320000 [==============================] - 12s 36us/step - loss: 0.2093 - acc: 0.9064 - val_loss: 0.2482 - val_acc: 0.8853\n",
      "Epoch 55/200\n",
      "320000/320000 [==============================] - 25s 79us/step - loss: 0.2082 - acc: 0.9069 - val_loss: 0.2475 - val_acc: 0.8843\n",
      "Epoch 56/200\n",
      "320000/320000 [==============================] - 21s 65us/step - loss: 0.2073 - acc: 0.9075 - val_loss: 0.2508 - val_acc: 0.8845\n",
      "Epoch 57/200\n",
      "320000/320000 [==============================] - 16s 50us/step - loss: 0.2064 - acc: 0.9082 - val_loss: 0.2497 - val_acc: 0.8845\n",
      "Epoch 58/200\n",
      "320000/320000 [==============================] - 11s 34us/step - loss: 0.2082 - acc: 0.9069 - val_loss: 0.2473 - val_acc: 0.8860\n",
      "Epoch 59/200\n",
      "320000/320000 [==============================] - 25s 79us/step - loss: 0.2059 - acc: 0.9082 - val_loss: 0.2476 - val_acc: 0.8844\n",
      "\n",
      "--- Learning curve of model training ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check against test data ---\n",
      "\n",
      "100000/100000 [==============================] - 3s 33us/step\n",
      "\n",
      "Accuracy on test data: 0.88\n",
      "\n",
      "Loss on test data: 0.25\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "numFeatures = len(X[0])\n",
    "print(\"Num of Features: \", numFeatures)\n",
    "\n",
    "\n",
    "DropoutAmount = 0.3\n",
    "NodesPerLayer= int((DropoutAmount*numFeatures)) + numFeatures + 1\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(2, activation='softmax'))\n",
    "print(model_m.summary())\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=2)\n",
    "]\n",
    "\n",
    "opt = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model_m.compile(loss='binary_crossentropy',\n",
    "                optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 475\n",
    "EPOCHS = 200\n",
    "\n",
    "history = model_m.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)\n",
    "\n",
    "\n",
    "print(\"\\n--- Learning curve of model training ---\\n\")\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['acc'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_acc'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.ylabel('Accuracy and Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Check against test data ---\\n\")\n",
    "\n",
    "\n",
    "#8 by 5, 9 by 5\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
    "print(\"\\nLoss on test data: %0.2f\" % score[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-22d15d8194d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msuspNum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "total = len(x_test)\n",
    "suspNum = 0\n",
    "\n",
    "for instance in y_test:\n",
    "    if instance[1] == 1:\n",
    "        suspNum += 1\n",
    "\n",
    "nonSUSPNum = total - suspNum\n",
    "print(\"Baseline: \", nonSUSPNum/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 192)               28416     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 192)               37056     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 214,082\n",
      "Trainable params: 214,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "139/139 [==============================] - 0s 69us/step\n",
      "True Positives:  9\n",
      "True Negatives:  105\n",
      "False Positives:  25\n",
      "False Negatives:  0\n",
      "\n",
      "Recall: 1.000\n",
      "Precision: 0.265\n",
      "Accuracy on test data: 0.820\n",
      "\n",
      "Loss on test data: 0.408\n",
      "Total Time:  0.010509967803955078\n",
      "Time Per:  2.1019935607910158e-08\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "modelName = \"5-5_and_4-5.h5\"\n",
    "\n",
    "data =  np.loadtxt('../data/canon_r3_c3.csv',dtype = float, delimiter = ',')\n",
    "#names = data[0]\n",
    "#data = data[1:]\n",
    "\n",
    "#Sets class data to y\n",
    "y_test = data[:,-1]\n",
    "#Choosing which features to include in X data Must be same as trained above\n",
    "x_test = data[:,3:-1]\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test) \n",
    "\n",
    "\n",
    "model = load_model(modelName)\n",
    "model.summary()\n",
    "\n",
    "first = time.time()\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total = end - first\n",
    "\n",
    "y_pred = model_m.predict(x_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)).ravel()\n",
    "\n",
    "print(\"True Positives: \", tp)\n",
    "print(\"True Negatives: \", tn)\n",
    "print(\"False Positives: \", fp)\n",
    "print(\"False Negatives: \", fn)\n",
    "\n",
    "\n",
    "suspNum = 0\n",
    "\n",
    "for instance in y_test:\n",
    "    if instance[1] == 1:\n",
    "        suspNum += 1\n",
    "\n",
    "print(\"\\nRecall: %0.3f\" % (tp/(tp+fn)))\n",
    "print(\"Precision: %0.3f\" % (tp/(tp+fp)))\n",
    "\n",
    "print(\"Accuracy on test data: %0.3f\" % score[1])\n",
    "print(\"\\nLoss on test data: %0.3f\" % score[0])\n",
    "\n",
    "print(\"Total Time: \", total)\n",
    "print(\"Time Per: \", total/len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
