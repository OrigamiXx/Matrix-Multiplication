{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2212e+04 1.2133e+04 2.3321e+04 3.2133e+04 2.3333e+04 4.4000e-01\n",
      " 3.2000e-01 2.4000e-01 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n",
      " 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[0.44 0.32 0.24 0.   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.\n",
      " 1.   0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   1.\n",
      " 0.   0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.\n",
      " 0.   1.   0.   0.   0.   1.   1.   0.   0.   0.   1.   0.   0.   0.\n",
      " 1.   1.   0.   0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   1.\n",
      " 0.   0.   1.   0.   0.   1.   0.   0.  ]\n",
      "200000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import utils\n",
    "import sys\n",
    "\n",
    "#Must Change if puzzle is a different size\n",
    "ROWS = 5\n",
    "COLUMNS = 5\n",
    "\n",
    "#Loads Training Data\n",
    "data =  np.loadtxt('../data/random_canon_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#names = data[0]\n",
    "#data = data[1:]\n",
    "\n",
    "\n",
    "#Loads Extra SUSP data to increase class percentage\n",
    "extraSUSPs = np.loadtxt('../data/random_canon_SUSPs_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#extraSUSPs = extraSUSPs[1:]\n",
    "\n",
    "\n",
    "#Creates one dataset\n",
    "data = np.concatenate([data, extraSUSPs])\n",
    "\n",
    "#Sets class data to y\n",
    "y = data[:,-1]\n",
    "\n",
    "#Choosing which features to include in X data\n",
    "#X = data[:,8:-1]\n",
    "print(data[0])\n",
    "\n",
    "X = data[:,5:-1]\n",
    "\n",
    "\n",
    "#X = X.astype(np.float)\n",
    "y = utils.to_categorical(y) #Done to make categorical loss functions work\n",
    "print(y)\n",
    "\n",
    "print(X[0])\n",
    "\n",
    "#le = preprocessing.LabelEncoder()\n",
    "\n",
    "#for i in range(ROWS+COLUMNS):\n",
    "#    X[:,i] = le.fit_transform(X[:,i])\n",
    "\n",
    "#cat_features = [0, 1, 2, 3 ,4 ,5 ,6 ,7 ,8 ,9]\n",
    "#enc = preprocessing.OneHotEncoder(categorical_features=cat_features)\n",
    "#enc.fit(X)\n",
    "\n",
    "#print(enc.n_values_)\n",
    "#print(enc.feature_indices_)\n",
    "#X = enc.transform(X).toarray()\n",
    "#print(X[0])\n",
    "\n",
    "\n",
    "#Creates a testing and training split that is stratified\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nfrom scipy import stats\\n\\nfrom sklearn import model_selection\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.svm import SVC\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.dummy import DummyClassifier\\nfrom sklearn.feature_selection import RFE\\n\\n\\n# prepare configuration for cross validation test harness\\nseed = 1\\n\\n# prepare models\\nmodels = []\\nmodels.append((\\'ZR\\', DummyClassifier(strategy=\"most_frequent\")))\\nmodels.append((\\'LR\\', LogisticRegression(solver=\\'liblinear\\')))\\n#models.append((\\'KN5\\', KNeighborsClassifier()))  # Too Slow commented out\\n#models.append((\\'KN7\\', KNeighborsClassifier(n_neighbors=7)))\\nmodels.append((\\'DT\\', DecisionTreeClassifier()))\\nmodels.append((\\'NB\\', GaussianNB()))\\n#models.append((\\'SVM\\', SVC(gamma=\\'auto\\')))\\n#models.append((\\'LIN\\', SVC(kernel=\\'linear\\',gamma=\\'auto\\')))\\n#models.append((\\'RF\\',RandomForestClassifier(n_estimators=100)))\\n\\n# evaluate each model in turn\\n# note that I\\'m going to run through each model above\\n# performing a 10-fold cross-validation each time\\n# (n_splits = 10), specifying \\'accuracy\\' as my measure\\n\\nresults = []\\nclassifiers = []\\nscoring = \\'accuracy\\'\\nfor name, model in models:\\n\\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\\n\\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\\n\\tresults.append(cv_results)\\n\\tclassifiers.append(name)\\n\\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\\n\\tprint(msg)\\n\\n    \\n    \\n# boxplot algorithm comparison\\n\\nfig = plt.figure()\\nfig.suptitle(\\'Algorithm Comparison\\')\\nax = fig.add_subplot(111)\\nplt.boxplot(results)\\nax.set_xticklabels(classifiers)\\nplt.show()\\n\\n#print(\\'\\n***Performing t-tests***\\n\\n\\')\\n\\n    \\n#ttest,pval = stats.ttest_rel(results[0], results[1])\\n#print(\\'P-Val between ZeroR and Logistic Regression: %.2f\\' % pval)\\n\\n#if pval<0.05:\\n#    print(\"reject null hypothesis\")\\n#else:\\n#    print(\"accept null hypothesis\") \\n\\n#print()    \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 1\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('ZR', DummyClassifier(strategy=\"most_frequent\")))\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "#models.append(('KN5', KNeighborsClassifier()))  # Too Slow commented out\n",
    "#models.append(('KN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC(gamma='auto')))\n",
    "#models.append(('LIN', SVC(kernel='linear',gamma='auto')))\n",
    "#models.append(('RF',RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "# note that I'm going to run through each model above\n",
    "# performing a 10-fold cross-validation each time\n",
    "# (n_splits = 10), specifying 'accuracy' as my measure\n",
    "\n",
    "results = []\n",
    "classifiers = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tclassifiers.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "    \n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(classifiers)\n",
    "plt.show()\n",
    "\n",
    "#print('\\n***Performing t-tests***\\n\\n')\n",
    "\n",
    "    \n",
    "#ttest,pval = stats.ttest_rel(results[0], results[1])\n",
    "#print('P-Val between ZeroR and Logistic Regression: %.2f' % pval)\n",
    "\n",
    "#if pval<0.05:\n",
    "#    print(\"reject null hypothesis\")\n",
    "#else:\n",
    "#    print(\"accept null hypothesis\") \n",
    "\n",
    "#print()    \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Features:  78\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 102)               8058      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 206       \n",
      "=================================================================\n",
      "Total params: 60,794\n",
      "Trainable params: 60,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.5118 - acc: 0.7406 - val_loss: 0.4727 - val_acc: 0.7445\n",
      "Epoch 2/200\n",
      "160000/160000 [==============================] - 4s 23us/step - loss: 0.4571 - acc: 0.7431 - val_loss: 0.4354 - val_acc: 0.7508\n",
      "Epoch 3/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.4234 - acc: 0.7559 - val_loss: 0.4041 - val_acc: 0.7731\n",
      "Epoch 4/200\n",
      "160000/160000 [==============================] - 4s 25us/step - loss: 0.3981 - acc: 0.7759 - val_loss: 0.3816 - val_acc: 0.7824\n",
      "Epoch 5/200\n",
      "160000/160000 [==============================] - 4s 25us/step - loss: 0.3797 - acc: 0.7879 - val_loss: 0.3700 - val_acc: 0.7937\n",
      "Epoch 6/200\n",
      "160000/160000 [==============================] - 4s 26us/step - loss: 0.3643 - acc: 0.7978 - val_loss: 0.3563 - val_acc: 0.7993\n",
      "Epoch 7/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.3520 - acc: 0.8054 - val_loss: 0.3494 - val_acc: 0.8042\n",
      "Epoch 8/200\n",
      "160000/160000 [==============================] - 5s 32us/step - loss: 0.3429 - acc: 0.8099 - val_loss: 0.3407 - val_acc: 0.8092\n",
      "Epoch 9/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.3354 - acc: 0.8154 - val_loss: 0.3342 - val_acc: 0.8103\n",
      "Epoch 10/200\n",
      "160000/160000 [==============================] - 7s 46us/step - loss: 0.3310 - acc: 0.8169 - val_loss: 0.3358 - val_acc: 0.8115\n",
      "Epoch 11/200\n",
      "160000/160000 [==============================] - 6s 39us/step - loss: 0.3277 - acc: 0.8207 - val_loss: 0.3318 - val_acc: 0.8137\n",
      "Epoch 12/200\n",
      "160000/160000 [==============================] - 4s 26us/step - loss: 0.3224 - acc: 0.8245 - val_loss: 0.3352 - val_acc: 0.8163\n",
      "Epoch 13/200\n",
      "160000/160000 [==============================] - 4s 25us/step - loss: 0.3196 - acc: 0.8259 - val_loss: 0.3294 - val_acc: 0.8150\n",
      "Epoch 14/200\n",
      "160000/160000 [==============================] - 4s 25us/step - loss: 0.3172 - acc: 0.8281 - val_loss: 0.3262 - val_acc: 0.8173\n",
      "Epoch 15/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.3154 - acc: 0.8293 - val_loss: 0.3285 - val_acc: 0.8143\n",
      "Epoch 16/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.3126 - acc: 0.8310 - val_loss: 0.3273 - val_acc: 0.8167\n",
      "Epoch 17/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.3098 - acc: 0.8336 - val_loss: 0.3252 - val_acc: 0.8176\n",
      "Epoch 18/200\n",
      "160000/160000 [==============================] - 4s 27us/step - loss: 0.3080 - acc: 0.8355 - val_loss: 0.3205 - val_acc: 0.8215\n",
      "Epoch 19/200\n",
      "160000/160000 [==============================] - 5s 33us/step - loss: 0.3059 - acc: 0.8363 - val_loss: 0.3217 - val_acc: 0.8215\n",
      "Epoch 20/200\n",
      "160000/160000 [==============================] - 5s 32us/step - loss: 0.3047 - acc: 0.8373 - val_loss: 0.3217 - val_acc: 0.8228\n",
      "Epoch 21/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.3022 - acc: 0.8387 - val_loss: 0.3215 - val_acc: 0.8210\n",
      "Epoch 22/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.3002 - acc: 0.8403 - val_loss: 0.3169 - val_acc: 0.8227\n",
      "Epoch 23/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2992 - acc: 0.8407 - val_loss: 0.3181 - val_acc: 0.8249\n",
      "Epoch 24/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2977 - acc: 0.8426 - val_loss: 0.3245 - val_acc: 0.8187\n",
      "Epoch 25/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2965 - acc: 0.8427 - val_loss: 0.3182 - val_acc: 0.8243\n",
      "Epoch 26/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2951 - acc: 0.8450 - val_loss: 0.3174 - val_acc: 0.8272\n",
      "Epoch 27/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2944 - acc: 0.8455 - val_loss: 0.3173 - val_acc: 0.8249\n",
      "Epoch 28/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2926 - acc: 0.8459 - val_loss: 0.3159 - val_acc: 0.8272\n",
      "Epoch 29/200\n",
      "160000/160000 [==============================] - 5s 33us/step - loss: 0.2915 - acc: 0.8465 - val_loss: 0.3177 - val_acc: 0.8264\n",
      "Epoch 30/200\n",
      "160000/160000 [==============================] - 5s 32us/step - loss: 0.2905 - acc: 0.8471 - val_loss: 0.3153 - val_acc: 0.8262\n",
      "Epoch 31/200\n",
      "160000/160000 [==============================] - 4s 27us/step - loss: 0.2884 - acc: 0.8490 - val_loss: 0.3148 - val_acc: 0.8296\n",
      "Epoch 32/200\n",
      "160000/160000 [==============================] - 4s 27us/step - loss: 0.2888 - acc: 0.8487 - val_loss: 0.3155 - val_acc: 0.8284\n",
      "Epoch 33/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2866 - acc: 0.8501 - val_loss: 0.3162 - val_acc: 0.8284\n",
      "Epoch 34/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2863 - acc: 0.8510 - val_loss: 0.3164 - val_acc: 0.8259\n",
      "Epoch 35/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2848 - acc: 0.8512 - val_loss: 0.3156 - val_acc: 0.8269\n",
      "Epoch 36/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2831 - acc: 0.8532 - val_loss: 0.3182 - val_acc: 0.8261\n",
      "Epoch 37/200\n",
      "160000/160000 [==============================] - 3s 22us/step - loss: 0.2832 - acc: 0.8533 - val_loss: 0.3156 - val_acc: 0.8287\n",
      "Epoch 38/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2818 - acc: 0.8534 - val_loss: 0.3168 - val_acc: 0.8280\n",
      "Epoch 39/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2805 - acc: 0.8540 - val_loss: 0.3158 - val_acc: 0.8279\n",
      "Epoch 40/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2802 - acc: 0.8548 - val_loss: 0.3134 - val_acc: 0.8283\n",
      "Epoch 41/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.2788 - acc: 0.8563 - val_loss: 0.3127 - val_acc: 0.8315\n",
      "Epoch 42/200\n",
      "160000/160000 [==============================] - 4s 24us/step - loss: 0.2782 - acc: 0.8567 - val_loss: 0.3134 - val_acc: 0.8301\n",
      "Epoch 43/200\n",
      "160000/160000 [==============================] - 3s 19us/step - loss: 0.2779 - acc: 0.8565 - val_loss: 0.3120 - val_acc: 0.8315\n",
      "Epoch 44/200\n",
      "160000/160000 [==============================] - 4s 23us/step - loss: 0.2764 - acc: 0.8579 - val_loss: 0.3159 - val_acc: 0.8273\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2757 - acc: 0.8582 - val_loss: 0.3158 - val_acc: 0.8282\n",
      "Epoch 46/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2758 - acc: 0.8577 - val_loss: 0.3131 - val_acc: 0.8281\n",
      "Epoch 47/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2748 - acc: 0.8589 - val_loss: 0.3105 - val_acc: 0.8320\n",
      "Epoch 48/200\n",
      "160000/160000 [==============================] - 4s 25us/step - loss: 0.2734 - acc: 0.8592 - val_loss: 0.3130 - val_acc: 0.8317\n",
      "Epoch 49/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2733 - acc: 0.8594 - val_loss: 0.3142 - val_acc: 0.8287\n",
      "Epoch 50/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2729 - acc: 0.8607 - val_loss: 0.3145 - val_acc: 0.8317\n",
      "Epoch 51/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2718 - acc: 0.8610 - val_loss: 0.3106 - val_acc: 0.8312\n",
      "Epoch 52/200\n",
      "160000/160000 [==============================] - 3s 18us/step - loss: 0.2705 - acc: 0.8619 - val_loss: 0.3093 - val_acc: 0.8329\n",
      "Epoch 53/200\n",
      "160000/160000 [==============================] - 3s 20us/step - loss: 0.2696 - acc: 0.8624 - val_loss: 0.3153 - val_acc: 0.8274\n",
      "Epoch 54/200\n",
      "160000/160000 [==============================] - 3s 20us/step - loss: 0.2690 - acc: 0.8632 - val_loss: 0.3151 - val_acc: 0.8289\n",
      "Epoch 55/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2701 - acc: 0.8622 - val_loss: 0.3147 - val_acc: 0.8272\n",
      "Epoch 56/200\n",
      "160000/160000 [==============================] - 3s 20us/step - loss: 0.2688 - acc: 0.8632 - val_loss: 0.3145 - val_acc: 0.8313\n",
      "Epoch 57/200\n",
      "160000/160000 [==============================] - 3s 20us/step - loss: 0.2675 - acc: 0.8645 - val_loss: 0.3157 - val_acc: 0.8306\n",
      "Epoch 58/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2676 - acc: 0.8644 - val_loss: 0.3124 - val_acc: 0.8304\n",
      "Epoch 59/200\n",
      "160000/160000 [==============================] - 3s 21us/step - loss: 0.2675 - acc: 0.8642 - val_loss: 0.3161 - val_acc: 0.8297\n",
      "\n",
      "--- Learning curve of model training ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check against test data ---\n",
      "\n",
      "50000/50000 [==============================] - 1s 24us/step\n",
      "\n",
      "Accuracy on test data: 0.83\n",
      "\n",
      "Loss on test data: 0.32\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "numFeatures = len(X[0])\n",
    "print(\"Num of Features: \", numFeatures)\n",
    "\n",
    "\n",
    "DropoutAmount = 0.3\n",
    "NodesPerLayer= int((DropoutAmount*numFeatures)) + numFeatures + 1\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu', input_shape=(numFeatures,)))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(NodesPerLayer, activation='relu'))\n",
    "model_m.add(Dropout(DropoutAmount))\n",
    "model_m.add(Dense(2, activation='softmax'))\n",
    "print(model_m.summary())\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=2)\n",
    "]\n",
    "\n",
    "opt = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model_m.compile(loss='binary_crossentropy',\n",
    "                optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 475\n",
    "EPOCHS = 200\n",
    "\n",
    "history = model_m.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)\n",
    "\n",
    "\n",
    "print(\"\\n--- Learning curve of model training ---\\n\")\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['acc'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_acc'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.ylabel('Accuracy and Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Check against test data ---\\n\")\n",
    "\n",
    "\n",
    "#8 by 5, 9 by 5\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
    "print(\"\\nLoss on test data: %0.2f\" % score[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:  0.74254\n"
     ]
    }
   ],
   "source": [
    "total = len(x_test)\n",
    "suspNum = 0\n",
    "\n",
    "for instance in y_test:\n",
    "    if instance[1] == 1:\n",
    "        suspNum += 1\n",
    "\n",
    "nonSUSPNum = total - suspNum\n",
    "print(\"Baseline: \", nonSUSPNum/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 102)               8058      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 102)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 206       \n",
      "=================================================================\n",
      "Total params: 60,794\n",
      "Trainable params: 60,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "50000/50000 [==============================] - 2s 30us/step\n",
      "True Positives:  11018\n",
      "True Negatives:  30497\n",
      "False Positives:  6630\n",
      "False Negatives:  1855\n",
      "\n",
      "Recall: 0.856\n",
      "Precision: 0.624\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d56246bc44fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on test data: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLoss on test data: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "modelName = \"best_model.52-0.31.h5\"\n",
    "\n",
    "#data =  np.loadtxt('../data/random_c_r5_c5.csv',dtype = float, delimiter = ',')\n",
    "#names = data[0]\n",
    "#data = data[1:]\n",
    "\n",
    "#Sets class data to y\n",
    "#y = data[:,-1]\n",
    "\n",
    "#Choosing which features to include in X data Must be same as trained above\n",
    "#X = data[:,5:-1]\n",
    "\n",
    "#y = keras.utils.to_categorical(y) \n",
    "\n",
    "\n",
    "\n",
    "model = load_model(modelName)\n",
    "model.summary()\n",
    "\n",
    "first = time.time()\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total = end - first\n",
    "\n",
    "y_pred = model_m.predict(x_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)).ravel()\n",
    "\n",
    "print(\"True Positives: \", tp)\n",
    "print(\"True Negatives: \", tn)\n",
    "print(\"False Positives: \", fp)\n",
    "print(\"False Negatives: \", fn)\n",
    "\n",
    "\n",
    "suspNum = 0\n",
    "\n",
    "for instance in y_test:\n",
    "    if instance[1] == 1:\n",
    "        suspNum += 1\n",
    "\n",
    "print(\"\\nRecall: %0.3f\" % (tp/(tp+fn)))\n",
    "print(\"Precision: %0.3f\" % (tp/(tp+fp)))\n",
    "\n",
    "print(\"Accuracy on test data: %0.3f\" % (tp+tn)/len(y_test))\n",
    "print(\"\\nLoss on test data: %0.3f\" % score[0])\n",
    "\n",
    "print(\"Total Time: \", total)\n",
    "print(\"Time Per: \", total/len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
