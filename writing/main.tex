\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{rpmacros}
\RequirePackage[colorlinks=true]{hyperref}
\hypersetup{
  linkcolor=[rgb]{0,0,0.4},
  citecolor=[rgb]{0, 0.4, 0},
  urlcolor=[rgb]{0.6, 0, 0}
}
\usepackage{mathpazo}
\usepackage{bbm}
\usepackage{todonotes}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{mdframed}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,backgrounds}

\usepackage[font=footnotesize]{caption}

\input{thmmacros}
\input{customurlbst/bibmacros}

\usepackage{algorithmicx}
\usepackage{algorithm} % http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}

\algrenewcommand\algorithmicindent{1.0em}%

\newcommand{\RPnote}[1]{\textcolor{BrickRed}{RP: #1}}
\newcommand{\Mattnote}[1]{\textcolor{OliveGreen}{MWA: #1}}
\newcommand{\BLnote}[1]{\textcolor{Blue}{BLV: #1}}
\newcommand{\Anote}[1]{\textcolor{Plum}{A: #1}}
\newcommand{\MFnote}[1]{\textcolor{DarkOrchid}{MF: #1}}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\newcommand\sse{\subseteq}
\newcommand\Sym[1]{\ensuremath{\mathrm{Sym}_{#1}}}

%\onehalfspacing
\date{}

\title{Matrix Multiplication: Finding Strong Uniquely-Solvable Puzzles
{\IfFileExists{./sha.tex}{\\\small SHA: \input{sha}}{}}}
\author{
Matthew Anderson\thanks{Department of Computer Science, Union College, Schenectady, New York, USA, E-mails: \texttt{andersm2@union.edu, jiz@union.edu, xua@union.edu}}%
\and%
Zongliang Ji\samethanks[1]
\and%
Anthony Yang Xu\samethanks[1]
}
\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\thispagestyle{empty}
\newpage
\pagenumbering{arabic}


\section{Introduction}
\label{sec:intro}

% Context

An optimal algorithm for matrix multiplication is remains elusive
despite substantial effort.  We focus on the square variant of the
matrix multiplication problem, that is, given two $n$-by-$n$ matrices
$A$ and $B$ over a field $\F$, the goal is to compute the matrix
product $C = A \times B$.  The question that arised is: How many field
operations are required to compute $C$.  The na\"{i}ve algorithm,
based on the mathematical definition of matrix product, runs in time
$O(n^3)$, and for a time it was thought to be the optimal algorithm.
It was surprising when Strassen showed that matrix multiplication can
be done in time $O(n^{2.808})$ \cite{str69}, using a
divide-and-conquer approach.  A long sequence of work concluding with
Coppersmith and Winograd's laser method that reduced the running time
to $O(2^{2.376})$ \cite{pan78,b79,sch81,cw82,str86,cw87}. Recent
computer-aided refinements of Coppersmith and Winograd's work done by
Stothers, Vassilevska-Williams, and Le Gall further reduced the
exponent to $\omega \le 2.3728639$ \cite{sto10,vas11,leg14}.

There are some lower bounds on the time complexity of matrix
multiplication.  Na\"{i}ely, the dimensions of the output matrix $C$
imply that the problem requires at least $\Omega(n^2)$ time.  Slightly
better lower bounds are also known for specialized models of
computation, like bounded-depth arithmetic circuits \cite{XXX}.  There
are also lower bounds known for a variety of algorithmic approaches
for matrix multiplication.  Ambainis et al showed that the laser
method, the approach of Coppersmith-Winograd and subsequent
refinements, cannot alone achieve an algorithm with $\omega \le
2.3078$ running time \cite{afl14}.

% Other lower bounds?
% Tensor rank approach
% - Lower bounds
% - Impossibility

% Motivation

Cohn and Umans \cite{cu03} introduced a program for developing faster
algorithms for matrix multiplication by reducing this question to a
search for groups with subsets that satisfy a certain algebraic
property called the \emph{triple-product property} that allows matrix
multiplication to be embed in the group algebra.  Subsequent work
\cite{cksu05} elaborated on this idea and developed the notion of
\emph{strong uniquely solvable puzzles} (SUSP) whose existence would
also imply faster matrix multiplication algorithms.

A \emph{width}-$k$ puzzle $P$ is a subset of $U_k = \set{0,1,2}^k$,
and the cardinality of $P$ is the puzzle's \emph{size}.  Each element
of $P$ is called a \emph{row} of $P$, and each row consists of three
\emph{subrows} which are elements of $\set{0,*}^k$, $\set{1,*}^k$,
$\set{2,*}^k$ respectively.  Informally, a puzzle $P$ is a uniquely
solvable puzzle if there is no way to permute the subrows of $P$
without overlap to form a distinct puzzle $P'$.  A uniquely solvable
puzzle is \emph{strong} if stronger condition for non-overlapping is
applied. For a fixed width $k$, the larger the size of a puzzle $P$,
the faster matrix multiplication algorithm it implies if $P$ is a SUSP
\cite[Corollary 3.6]{cksu05}.  In fact Cohn et al.~show that there
exist an infinite family of SUSP that achieve $w < 2.48$
\cite[Proposition 3.8]{cksu05}.

% Approach

We follow Cohn and Umans' program simulateneously from theoretical and
experimental perspectives.  We explore properties of SUSP, develop
\emph{verification} algorithms for determining whether a puzzle is a
SUSP, develop \emph{search} algorithms for searching for large SUSP,
and implement these algorithms in desktop and high performance
computing settings.  From the computational complexity perspective the
algorithms we develop to verify and search for SUSP are not efficient
as they run in exponential or doubly exponential time in the natural
parameters.  However, as the goal is to find a sufficiently large SUSP
which in turn produces a fast matrix multiplication algorithm, the
inefficiency of our algorithms does not directly impact the efficiency
of the matrix multiplication algorithms.  Rather, it indirectly
impacts the efficiency by limiting the search space of puzzles that we
can practically examine.

% Results

In addition to the various theoretical results, we have experimental
results that bound the size of the largest SUSP for small width
puzzles.  For small constant width the bounds are tight, though the
tightness of the results decreases as width increases.  Lower bounds
on size are witnessed by examples of SUSP we found via search and
constructions that compose SUSP of small width into SUSP of larger
width while maintaining the relative size of the SUSP.  Upper bounds
are determined computationally by evaluating admissible heuristics on
the initial levels of the puzzle search tree.  Although our current
experimental results do not beat Proposition 3.8 of \cite{cksu05} for
unbounded $k$, they do suggest there is considerable room for
improvement.

% Organization
\paragraph{Organization}
We begin with formal definitions and properties of puzzles and strong
uniquely solvable puzzles in \autoref{sec:prelim}.  In
\autoref{sec:verify} we discuss our algorithms for verifying that a
puzzle is a SUSP.  In \autoref{sec:heuristic} we describe fast,
but incomplete, heuristics for verifying SUSP.
\autoref{sec:search} explains our search algorithms.
\autoref{sec:results} discuss our implementation, experiments, and
the experimental results.


\section{Preliminaries}
\label{sec:prelim}

\newcommand\ordset[1]{\ensuremath{[#1]}}

We use $\ordset{n}$ to denote the set $\set{0,1,2,\ldots, n-1}$.  For
a set $Q$, $\Sym{Q}$ denotes the symmetric group on the elements of
$Q$.  \cite{cksu05} introduced the idea of a \emph{puzzle}.

\begin{definition}[Puzzle]
  For $s, k \in \Natural$, an $(s,k)$-\emph{puzzle} is a
  subset $P \sse U_k = \ordset{3}^k$ with $|P| = s$.
\end{definition}

We say that an $(s,k)$-puzzle has $s$ rows and $k$ columns.  The
columns are inherent ordered and indexed by $\ordset{k}$.  The rows are not
inherently ordered, however, it is often convienent to assume that the
rows are arbitrarily ordered and indexed by $\ordset{s}$.

\cite{cksu05} also establish a particular combinatorial property of
such puzzles that can derive groups that matrix multiplication can be
embedded into.  Such puzzles are called \emph{strong} uniquely
solvable puzzles.  However, to give some intuition we first explain a
simpler version of the property called \emph{uniquely solvable
  puzzles}.

\begin{definition}[Uniquely Solvable Puzzle (USP)]
  ~\\An $(s,k)$-puzzle $P$ is \emph{uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that at least two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
\end{definition}

Informally a puzzle is \textbf{not} uniquely solvable if each row of
the puzzle can be broken into zeros, ones, and twos pieces and then
the rows can be reassembled in a different way so that each new row is
a combination of a zeroes, a ones, and twos piece where there is
exactly element of $\ordset{3}$ for each column.  Observe that uniquely
solvable puzzles can have at most $2^k$ rows because each zeroes
piece, ones piece, and two piece must be unique, as otherwise the
duplicate pieces can be swapped making the puzzle not uniquely
solvable.  The definition of \emph{strong} uniquely solvable puzzle is
below, it is nearly the same except that it requires that there be a
collision on a column between exactly two pieces, not two or more
pieces like in the original definition.

\begin{definition}[Strong Uniquely Solvable Puzzle]
  ~\\
  An $(s,k)$-puzzle $P$ is \emph{strong uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that exactly two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
  
\end{definition}

Observe that the properties of uniquely solvable and strong uniquely
solvable are invariant to the ordering of the rows or columns of a
puzzle.  This fact is used implicitly.  Also note that these
properties are invariant to maps between puzzles induced by
permutations from \Sym{\ordset{3}} on the puzzle cell elements.

Cohn et al.~ show the following connection between the existence of
strong uniquely solvable puzzles and upper bounds on the exponent of
matrix multiplication $\omega$.

\begin{lemma}[{\cite[Corollary 3.6]{cksu05}}]
  If there is a strong uniquely solvable $(s,k)$-puzzle,
  $$\omega \le \min_{m \ge 3, m \in \Natural} \frac{3 \log
    m}{\log(m-1)} - \frac{3 \log s!}{sk \log(m-1)}.$$
\end{lemma}

In the same article, the authors also demonstrate the existence of an
infinite family of strong uniquely solvable puzzles that achieves a
non-trivial bound on $\omega$.

\begin{lemma}[{\cite[Proposition 3.8]{cksu05}}]
  There is an infinite family of strong uniquely solvable puzzles that
  achieves $\omega < 2.48$.
\end{lemma}

Finally, they conjecture that strong uniquely solvable puzzles provide
a root to achieving quadratic time matrix multiplication.

\begin{conjecture}[{\cite{cksu05}}]
  There exists a family of strong uniquely solvable puzzles that
  implies $\omega = 2$.
\end{conjecture}

Unfortunately, this conjecture was recently shown to be false.

\begin{lemma}[\cite{bccgu16}]
  Strong uniquely solvable puzzles cannot show $\omega < 2 +
  \epsilon$, for some $\epsilon > 0$.
\end{lemma}

This result is a consequence of a recent breakthrough arithmetic
progressions in cap sets \cite{e16,clp16} combined with a conditional
result on the Erd\"{o}s-Szemeredi sunflower conjecture \cite{asu13}.
The results of \cite{bccgu16} do imply that Cohn and Umans' strong
uniquely solvable puzzle approach cannot achieve the ideal $\omega =
2$.  However, we are unaware of a concrete lower bound on $\epsilon$
implies by this result.  This means there is a still a substantial gap
in our understanding between what has been acheived by the refinements
of LeGall, Williams, and Stothers, and the impossibility of showing
$\omega = 2$ using the Cohn and Umans' approach.



\section{Verifying for Strong USPs}
\label{sec:verify}

\subsection{3DM to 3SAT}
\label{subsec:3sat}

\section{Heuristics for Strong USPs}
\label{sec:heuristic}

Despite our efforts devise an exact algorithm for verifying strong
USPs, the performance of the final algorithm was not practical.  To
speed the algorithm up we considered a number of verification
heuristics that were fast to evaluate, but did not alway produce a
definitive answer.  The heuristics output YES, NO, or MAYBE to whether
a given puzzle $P$ was a strong USP.  We consider only Las Vegas
algorithms here, that is, algorithms whose output of YES or NO is
always correct.  To verify a puzzle $P$ we run a battery of fast
heuristics and return early if any of the heuristics produce a
definitive YES or NO.  When all the heuristics result in MAYBE then
run one of the slower exact algorithms that were discussed in the
previous section.  Most of the heuristics we considered were
deterministic, but a few were randomized.  This is again in the Las
Vegas sense: An output of YES or NO is always correct, but as function
of the input and internal algorthmic randomness MAYBE can be also be
output and can vary between independent runs.  The heuristics have
several different forms, but all rely ultimately on structural
properties of strong USP.

\subsection{Downward Closed}

The simplest heuristics we considered were based on the fact that
strong USP are downward closed, that is, if $P$ is a strong USP, then
so is every subpuzzle $P' \sse P$.  This leads to practical heuristic
that can determine that a puzzle is not a strong USP.

\begin{algorithm}
  \caption{: Downward-closed heuristic}
  \label{alg:k-read-pit}
\begin{algorithmic}[1]
  \Require{an $(s,k)$-puzzle $P$, and size $s' \le s$.}
  \Ensure{NO, if $P$ has a set of $s'$ rows that do not form a strong USP, and MAYBE otherwise.}
  \For{$P' \sse P, |P'| = s'$}
      \If{$P'$ is not a strong USP}
          \Return{NO}
      \EndIf
  \EndFor{}
  \State{\Return{MAYBE}}
\end{algorithmic}
\end{algorithm}

This algorithm runs in time $O(s^{s'} T(s', k))$ where $T(s',k)$ is
the running time for exactly verifying a $(s',k)$-puzzle.  In practice
we did not apply this heuristic for $s'$ larger than $3$, so the
effective running time was $O(s^3 T(3,k))$, which is polynomial in $s$
and $k$ using the verification algorithms from the previous section
which eliminate dependence on $k$ for polynomial cost.  This heuristic
can be made even more practical by caching the results for puzzles of
size $s'$, reducing the verification time per iteration to constant in
exchange for $O(2^{s'k}T(s',k))$ time to precompute the values for all
puzzles of size $s'$.  There is also space overhead because the
precomputed results are being cached.

Note that since our search algorithms typically start from a known
strong USP and tries to add rows, looking a subsets of a puzzle that
have already been verified is wasteful -- these are skipped over in
this setting.  From a practical point of view, running this heuristic
is free for small constant $s'$, as the exact verification algorithms
have a matching or higher polynomial running time.  Furthermore, since
the algorithm can return early, its expected running time on random
non-strong USPs is low.  There appeared to be dimenishing returns with
increasing $s'$ as it substantially increases precompute time and
storage while each stored value contributes relatively less to
verification as there are now many more values stored.

\subsection{Random Greedy}

This heuristic attempts to solve the 3D-Matching instance associated
with verifying a puzzle $P$ (discussed in \auto{sec:3DM}).  The
heuristic proceeds iteratively, determining the layer of the 3DM
instance with the least edges and randomly selecting an edge in that
layer to put into the 3DM.  If the heuristic successfully contructs a
3DM it returns NO indicating that the input puzzle $P$ is not a strong
USP.  If the heuristic reaches point were prior commits have made the
matching infeasible, the heuristic starts again from scratch.  This
process is repeated some number of times before it gives up and
returns MAYBE.  In our practical implementation we use $s^3$
iterations because the time balances well with the other heuristics
and effectively reduced the number of instances requiring a full
verification.

\subsection{Graph Automorphism}



\subsection{2D Matching}



\section{Searching for Strong USPs}
\label{sec:search}

\section{Experimental Results}
\label{sec:results}

\subsection{Strong USPs Found}
\label{subsec:usps_found}

\begin{figure}
  \label{fig:examples}
  \begin{multicols}{4}
  (1,1):\\[.5ex]
  \begin{tabular}{|c|}
    \hline
    1 \\ \hline
  \end{tabular}\\[6ex]

  (2,2):\\[.5ex]
  \begin{tabular}{|c|c|}
    \hline
    1&3 \\ \hline
    2&1 \\ \hline
  \end{tabular}\\[16ex]

  (3,3):\\[.5ex]
  \begin{tabular}{|c|c|c|}
    \hline
    1&1&1 \\ \hline
    3&2&1 \\ \hline
    3&3&2 \\ \hline
    \end{tabular}\\[2ex]

  (5,4):\\[.5ex]
  \begin{tabular}{|c|c|c|c|}
    \hline
    3&1&3&2 \\ \hline
    1&2&3&2 \\ \hline
    1&1&1&3 \\ \hline 
    3&2&1&3 \\ \hline 
    3&3&2&3 \\ \hline
  \end{tabular}\\[10ex]

  (8,5):\\[.5ex]
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    3&3&3&1&1 \\ \hline
    1&1&2&2&1 \\ \hline
    2&1&3&3&2 \\ \hline
    3&2&2&2&3 \\ \hline
    2&1&2&1&3 \\ \hline
    2&2&3&1&2 \\ \hline
    3&2&3&2&1 \\ \hline
    3&1&2&1&1 \\ \hline
  \end{tabular}\\[16ex]
    
  (14,6):\\[.5ex]
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    2&3&3&1&1&1 \\ \hline
    2&1&1&2&1&1 \\ \hline
    3&3&1&2&1&1 \\\hline
    3&2&2&2&1&1 \\\hline
    2&3&1&1&2&1 \\\hline
    2&2&3&1&2&1 \\\hline
    3&3&1&3&2&1 \\\hline
    3&2&3&3&2&1 \\\hline
    2&1&1&3&1&2 \\\hline
    2&3&1&3&2&2 \\\hline
    3&1&1&1&1&3 \\\hline
    3&3&2&3&1&3 \\\hline
    3&3&2&1&2&3 \\\hline
    2&2&3&2&2&3 \\\hline
  \end{tabular}
  \end{multicols}
  \caption{Respresentative examples of the largest strong uniquely
    solvable $(s,k)$-puzzles found from width $k = 1$ to $6$.}
\end{figure}

\autoref{table:compare} summarizes our main results which are
improved bounds on the maximum size of strong uniquely solvable
puzzles and compares them to bounds from \cite{cksu05}.  XXX
\begin{table}
  \label{table:compare}
  \begin{center}
  \begin{tabular}{|c|r|r|r|r|}
    \hline
    & \multicolumn{2}{|c|}{[CKSU05]} & \multicolumn{2}{|c|}{This work} \\
    \hline
    $k$ & Maximum $s$ & $\omega^*$~ & Maximum $s$ & $\omega^*$~\\
    \hline
    1 & $s\le ~~~~1$ & & $1=s$ & $3.000$  \\
    2 & $s\le ~~~~3$ & & $2=s$ & $2.670$ \\
    3 & $3 \le s \le ~~~~6$ & $2.642$ & $3=s$ & $2.642$ \\
    4 & $s\le ~~12$ & & $5=s$ & $2.585$ \\
    5 & $s\le ~~24$ & & $8=s$ & $2.562$  \\
    6 & $10 \le s \le ~~45$ & $2.615$ &$14\le s$ & $2.521$\\
    7 & $s\le ~~86$ & & $21\le s$ & $2.531$ \\
    8 & $s\le 162$ & & $30\le s$ & $2.547$ \\
    9 & $36 \le s \le 307$ & $2.592$ &$42\le s$ & $2.563$  \\
    \hline
  \end{tabular}
  \end{center}
  \caption{Comparison of bounds on maximum size of strong uniquely
    solvable $(s,k)$-puzzles with \cite{cksu05}.  $\omega^*$ is the
    $\omega$ in the limit of composing puzzles of these dimensions via
    direct product.}
\end{table}
  
\subsection{Algorithm Performance}
\label{subsec:performance}

\section{Conclusions}
\label{sec:conclusion}



\bibliographystyle{customurlbst/alphaurlpp} \bibliography{references}

\appendix


\end{document}
