\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{rpmacros}
\RequirePackage[colorlinks=true]{hyperref}
\hypersetup{
  linkcolor=[rgb]{0,0,0.4},
  citecolor=[rgb]{0, 0.4, 0},
  urlcolor=[rgb]{0.6, 0, 0}
}
\usepackage{mathpazo}
\usepackage{bbm}
\usepackage{todonotes}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{mdframed}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,backgrounds}

\usepackage[font=footnotesize]{caption}

\input{thmmacros}
\input{customurlbst/bibmacros}

\usepackage{algorithmicx}
\usepackage{algorithm} % http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}

\algrenewcommand\algorithmicindent{1.0em}%

\newcommand{\RPnote}[1]{\textcolor{BrickRed}{RP: #1}}
\newcommand{\Mattnote}[1]{\textcolor{OliveGreen}{MWA: #1}}
\newcommand{\BLnote}[1]{\textcolor{Blue}{BLV: #1}}
\newcommand{\Anote}[1]{\textcolor{Plum}{A: #1}}
\newcommand{\MFnote}[1]{\textcolor{DarkOrchid}{MF: #1}}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\newcommand\sse{\subseteq}
\newcommand\Sym[1]{\ensuremath{\mathrm{Sym}_{#1}}}

%\onehalfspacing
\date{}

\title{Matrix Multiplication: Finding Strong Uniquely-Solvable Puzzles
{\IfFileExists{./sha.tex}{\\\small SHA: \input{sha}}{}}}
\author{
Matthew Anderson\thanks{Department of Computer Science, Union College, Schenectady, New York, USA, E-mails: \texttt{andersm2@union.edu, jiz@union.edu, xua@union.edu}}%
\and%
Zongliang Ji\samethanks[1]
\and%
Anthony Yang Xu\samethanks[1]
}
\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\thispagestyle{empty}
\newpage
\pagenumbering{arabic}


\section{Introduction}
\label{sec:intro}

% Context

An optimal algorithm for matrix multiplication is remains elusive
despite substantial effort.  We focus on the square variant of the
matrix multiplication problem, that is, given two $n$-by-$n$ matrices
$A$ and $B$ over a field $\F$, the goal is to compute the matrix
product $C = A \times B$.  The question that arised is: How many field
operations are required to compute $C$.  The na\"{i}ve algorithm,
based on the mathematical definition of matrix product, runs in time
$O(n^3)$, and for a time it was thought to be the optimal algorithm.
It was surprising when Strassen showed that matrix multiplication can
be done in time $O(n^{2.808})$ \cite{str69}, using a
divide-and-conquer approach.  A long sequence of work concluding with
Coppersmith and Winograd's laser method that reduced the running time
to $O(2^{2.376})$ \cite{pan78,b79,sch81,cw82,str86,cw87}. Recent
computer-aided refinements of Coppersmith and Winograd's work done by
Stothers, Vassilevska-Williams, and Le Gall further reduced the
exponent to $\omega \le 2.3728639$ \cite{sto10,vas11,leg14}.

There are some lower bounds on the time complexity of matrix
multiplication.  Na\"{i}ely, the dimensions of the output matrix $C$
imply that the problem requires at least $\Omega(n^2)$ time.  Slightly
better lower bounds are also known for specialized models of
computation, like bounded-depth arithmetic circuits \cite{XXX}.  There
are also lower bounds known for a variety of algorithmic approaches
for matrix multiplication.  Ambainis et al showed that the laser
method, the approach of Coppersmith-Winograd and subsequent
refinements, cannot alone achieve an algorithm with $\omega \le
2.3078$ running time \cite{afl14}.

% Other lower bounds?
% Tensor rank approach
% - Lower bounds
% - Impossibility

% Motivation

Cohn and Umans \cite{cu03} introduced a program for developing faster
algorithms for matrix multiplication by reducing this question to a
search for groups with subsets that satisfy a certain algebraic
property called the \emph{triple-product property} that allows matrix
multiplication to be embed in the group algebra.  Subsequent work
\cite{cksu05} elaborated on this idea and developed the notion of
\emph{strong uniquely solvable puzzles} (SUSP) whose existence would
also imply faster matrix multiplication algorithms.

A \emph{width}-$k$ puzzle $P$ is a subset of $U_k = \set{0,1,2}^k$,
and the cardinality of $P$ is the puzzle's \emph{size}.  Each element
of $P$ is called a \emph{row} of $P$, and each row consists of three
\emph{subrows} which are elements of $\set{0,*}^k$, $\set{1,*}^k$,
$\set{2,*}^k$ respectively.  Informally, a puzzle $P$ is a uniquely
solvable puzzle if there is no way to permute the subrows of $P$
without overlap to form a distinct puzzle $P'$.  A uniquely solvable
puzzle is \emph{strong} if stronger condition for non-overlapping is
applied. For a fixed width $k$, the larger the size of a puzzle $P$,
the faster matrix multiplication algorithm it implies if $P$ is a SUSP
\cite[Corollary 3.6]{cksu05}.  In fact Cohn et al.~show that there
exist an infinite family of SUSP that achieve $w < 2.48$
\cite[Proposition 3.8]{cksu05}.

% Approach

We follow Cohn and Umans' program simulateneously from theoretical and
experimental perspectives.  We explore properties of SUSP, develop
\emph{verification} algorithms for determining whether a puzzle is a
SUSP, develop \emph{search} algorithms for searching for large SUSP,
and implement these algorithms in desktop and high performance
computing settings.  From the computational complexity perspective the
algorithms we develop to verify and search for SUSP are not efficient
as they run in exponential or doubly exponential time in the natural
parameters.  However, as the goal is to find a sufficiently large SUSP
which in turn produces a fast matrix multiplication algorithm, the
inefficiency of our algorithms does not directly impact the efficiency
of the matrix multiplication algorithms.  Rather, it indirectly
impacts the efficiency by limiting the search space of puzzles that we
can practically examine.

% Results

In addition to the various theoretical results, we have experimental
results that bound the size of the largest SUSP for small width
puzzles.  For small constant width the bounds are tight, though the
tightness of the results decreases as width increases.  Lower bounds
on size are witnessed by examples of SUSP we found via search and
constructions that compose SUSP of small width into SUSP of larger
width while maintaining the relative size of the SUSP.  Upper bounds
are determined computationally by evaluating admissible heuristics on
the initial levels of the puzzle search tree.  Although our current
experimental results do not beat Proposition 3.8 of \cite{cksu05} for
unbounded $k$, they do suggest there is considerable room for
improvement.

% Organization
\paragraph{Organization}
We begin with formal definitions and properties of puzzles and strong
uniquely solvable puzzles in Section~\ref{sec:prelim}.  In
Section~\ref{sec:check} we discuss our algorithms for verifying that a
puzzle is a SUSP.  In Section~\ref{sec:heuristic} we describe fast,
but incomplete, heuristics for verifying SUSP.
Section~\ref{sec:search} explains our search algorithms.
Section~\ref{sec:results} discuss our implementation, experiments, and
the experimental results.

\section{Checking for Strong USPs}
\label{sec:check}

\subsection{3DM to 3SAT}
\label{subsec:3sat}

\section{Heuristics for Strong USPs}
\label{sec:heuristic}

\section{Searching for Strong USPs}
\label{sec:search}

\section{Experimental Results}
\label{sec:results}

\subsection{Strong USPs Found}
\label{subsec:usps_found}

\subsection{Algorithm Performance}
\label{subsec:performance}

\section{Conclusions}


\section{Preliminaries}
\label{sec:prelim}

\newcommand\ordset[1]{\ensuremath{[#1]}}

We use $\ordset{n}$ to denote the set $\set{0,1,2,\ldots, n-1}$.  For
a set $Q$, $\Sym{Q}$ denotes the symmetric group on the elements of
$Q$.  \cite{cksu05} introduced the idea of a \emph{puzzle}.

\begin{definition}[Puzzle]
  For $s, k \in \Natural$, an $(s,k)$-\emph{puzzle} is a
  subset $P \sse U_k = \ordset{3}^k$ with $|P| = s$.
\end{definition}

We say that an $(s,k)$-puzzle has $s$ rows and $k$ columns.  The
columns are inherent ordered and indexed by $\ordset{k}$.  The rows are not
inherently ordered, however, it is often convienent to assume that the
rows are arbitrarily ordered and indexed by $\ordset{s}$.

\cite{cksu05} also establish a particular combinatorial property of
such puzzles that can derive groups that matrix multiplication can be
embedded into.  Such puzzles are called \emph{strong} uniquely
solvable puzzles.  However, to give some intuition we first explain a
simpler version of the property called \emph{uniquely solvable
  puzzles}.

\begin{definition}[Uniquely Solvable Puzzle (USP)]
  ~\\An $(s,k)$-puzzle $P$ is \emph{uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that at least two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
\end{definition}

Informally a puzzle is \textbf{not} uniquely solvable if each row of
the puzzle can be broken into zeros, ones, and twos pieces and then
the rows can be reassembled in a different way so that each new row is
a combination of a zeroes, a ones, and twos piece where there is
exactly element of $\ordset{3}$ for each column.  Observe that uniquely
solvable puzzles can have at most $2^k$ rows because each zeroes
piece, ones piece, and two piece must be unique, as otherwise the
duplicate pieces can be swapped making the puzzle not uniquely
solvable.  The definition of \emph{strong} uniquely solvable puzzle is
below, it is nearly the same except that it requires that there be a
collision on a column between exactly two pieces, not two or more
pieces like in the original definition.

\begin{definition}[Strong Uniquely Solvable Puzzle]
  ~\\
  An $(s,k)$-puzzle $P$ is \emph{strong uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that exactly two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
  
\end{definition}

Observe that the properties of uniquely solvable and strong uniquely
solvable are invariant to the ordering of the rows or columns of a
puzzle.  This fact is used implicitly.  Also note that these
properties are invariant to maps between puzzles induced by
permutations from \Sym{\ordset{3}} on the puzzle cell elements.

Cohn et al.~ show the following connection between the existence of
strong uniquely solvable puzzles and upper bounds on the exponent of
matrix multiplication $\omega$.

\begin{lemma}[{\cite[Corollary 3.6]{cksu05}}]
  If there is a strong uniquely solvable $(s,k)$-puzzle,
  $$\omega \le \min_{m \ge 3, m \in \Natural} \frac{3 \log
    m}{\log(m-1)} - \frac{3 \log s!}{sk \log(m-1)}.$$
\end{lemma}

In the same article, the authors also demonstrate the existence of an
infinite family of strong uniquely solvable puzzles that achieves a
non-trivial bound on $\omega$.

\begin{lemma}[{\cite[Proposition 3.8]{cksu05}}]
  There is an infinite family of strong uniquely solvable puzzles that
  achieves $\omega < 2.48$.
\end{lemma}

Finally, they conjecture that strong uniquely solvable puzzles provide
a root to achieving quadratic time matrix multiplication.

\begin{conjecture}[{\cite{cksu05}}]
  There exists a family of strong uniquely solvable puzzles that
  implies $\omega = 2$.
\end{conjecture}

Unfortunately, this conjecture was recently shown to be false.

\begin{lemma}[\cite{bccgu16}]
  Strong uniquely solvable puzzles cannot show $\omega < 2 +
  \epsilon$, for some $\epsilon > 0$.
\end{lemma}

This result is a consequence of a recent breakthrough arithmetic
progressions in cap sets \cite{e16,clp16} combined with a conditional
result on the Erd\"{o}s-Szemeredi sunflower conjecture \cite{asu13}.
The results of \cite{bccgu16} do imply that Cohn and Umans' strong
uniquely solvable puzzle approach cannot achieve the ideal $\omega =
2$.  However, we are unaware of a concrete lower bound on $\epsilon$
implies by this result.  This means there is a still a substantial gap
in our understanding between what has been acheived by the refinements
of LeGall, Williams, and Stothers, and the impossibility of showing
$\omega = 2$ using the Cohn and Umans' approach.



\section{Checking for Strong USPs}
\label{sec:check}

\subsection{3DM to 3SAT}
\label{subsec:3sat}

\section{Heuristics for Strong USPs}
\label{sec:heuristic}

\section{Searching for Strong USPs}
\label{sec:search}

\section{Results}
\label{sec:results}

\subsection{Strong USPs Found}
\label{subsec:usps_found}

\subsection{Algorithm Performance}
\label{subsec:performance}

\section{Conclusions}
\label{sec:conclusion}



\bibliographystyle{customurlbst/alphaurlpp} \bibliography{references}

\appendix


\end{document}
