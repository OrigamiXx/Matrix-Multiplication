\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{rpmacros}
\RequirePackage[colorlinks=true]{hyperref}
\hypersetup{
  linkcolor=[rgb]{0,0,0.4},
  citecolor=[rgb]{0, 0.4, 0},
  urlcolor=[rgb]{0.6, 0, 0}
}
\usepackage{mathpazo}
\usepackage{bbm}
\usepackage{todonotes}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{mdframed}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,backgrounds}

\usepackage[font=footnotesize]{caption}

\input{thmmacros}
\input{customurlbst/bibmacros}

\usepackage{algorithmicx}
\usepackage{algorithm} % http://ctan.org/pkg/algorithms
\usepackage[noend]{algpseudocode}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}


\algrenewcommand\algorithmicindent{1.0em}%

\newcommand{\RPnote}[1]{\textcolor{BrickRed}{RP: #1}}
\newcommand{\Mattnote}[1]{\textcolor{OliveGreen}{MWA: #1}}
\newcommand{\BLnote}[1]{\textcolor{Blue}{BLV: #1}}
\newcommand{\Anote}[1]{\textcolor{Plum}{A: #1}}
\newcommand{\MFnote}[1]{\textcolor{DarkOrchid}{MF: #1}}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\newcommand\sse{\subseteq}
\newcommand\Sym[1]{\ensuremath{\mathrm{Sym}_{#1}}}
\newcommand\condset[2]{\set{#1 \;|\; #2}}

%\onehalfspacing
\date{}

\title{Matrix Multiplication: Finding Strong Uniquely-Solvable Puzzles
{\IfFileExists{./sha.tex}{\\\small SHA: \input{sha}}{}}}
\author{
Matthew Anderson\thanks{Department of Computer Science, Union College, Schenectady, New York, USA, E-mails: \texttt{andersm2@union.edu, jiz@union.edu, xua@union.edu}}%
\and%
Zongliang Ji\samethanks[1]
\and%
Anthony Yang Xu\samethanks[1]
}
\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\thispagestyle{empty}
\newpage
\pagenumbering{arabic}


\section{Introduction}
\label{sec:intro}

% Context

An optimal algorithm for matrix multiplication is remains elusive
despite substantial effort.  We focus on the square variant of the
matrix multiplication problem, that is, given two $n$-by-$n$ matrices
$A$ and $B$ over a field $\F$, the goal is to compute the matrix
product $C = A \times B$.  The question that arised is: How many field
operations are required to compute $C$.  The na\"{i}ve algorithm,
based on the mathematical definition of matrix product, runs in time
$O(n^3)$, and for a time it was thought to be the optimal algorithm.
It was surprising when Strassen showed that matrix multiplication can
be done in time $O(n^{2.808})$ \cite{str69}, using a
divide-and-conquer approach.  A long sequence of work concluding with
Coppersmith and Winograd's laser method that reduced the running time
to $O(2^{2.376})$ \cite{pan78,b79,sch81,cw82,str86,cw87}. Recent
computer-aided refinements of Coppersmith and Winograd's work done by
Stothers, Vassilevska-Williams, and Le Gall further reduced the
exponent to $\omega \le 2.3728639$ \cite{sto10,vas11,leg14}.

There are some lower bounds on the time complexity of matrix
multiplication.  Na\"{i}ely, the dimensions of the output matrix $C$
imply that the problem requires at least $\Omega(n^2)$ time.  Slightly
better lower bounds are also known for specialized models of
computation, like bounded-depth arithmetic circuits \cite{XXX}.  There
are also lower bounds known for a variety of algorithmic approaches
for matrix multiplication.  Ambainis et al showed that the laser
method, the approach of Coppersmith-Winograd and subsequent
refinements, cannot alone achieve an algorithm with $\omega \le
2.3078$ running time \cite{afl14}.

% Other lower bounds?
% Tensor rank approach
% - Lower bounds
% - Impossibility

% Motivation

Cohn and Umans \cite{cu03} introduced a program for developing faster
algorithms for matrix multiplication by reducing this question to a
search for groups with subsets that satisfy a certain algebraic
property called the \emph{triple-product property} that allows matrix
multiplication to be embed in the group algebra.  Subsequent work
\cite{cksu05} elaborated on this idea and developed the notion of
\emph{strong uniquely solvable puzzles} (SUSP) whose existence would
also imply faster matrix multiplication algorithms.

A \emph{width}-$k$ puzzle $P$ is a subset of $U_k = \set{0,1,2}^k$,
and the cardinality of $P$ is the puzzle's \emph{size}.  Each element
of $P$ is called a \emph{row} of $P$, and each row consists of three
\emph{subrows} which are elements of $\set{0,*}^k$, $\set{1,*}^k$,
$\set{2,*}^k$ respectively.  Informally, a puzzle $P$ is a uniquely
solvable puzzle if there is no way to permute the subrows of $P$
without overlap to form a distinct puzzle $P'$.  A uniquely solvable
puzzle is \emph{strong} if stronger condition for non-overlapping is
applied. For a fixed width $k$, the larger the size of a puzzle $P$,
the faster matrix multiplication algorithm it implies if $P$ is a SUSP
\cite[Corollary 3.6]{cksu05}.  In fact Cohn et al.~show that there
exist an infinite family of SUSP that achieve $w < 2.48$
\cite[Proposition 3.8]{cksu05}.

% Approach

We follow Cohn and Umans' program simulateneously from theoretical and
experimental perspectives.  We explore properties of SUSP, develop
\emph{verification} algorithms for determining whether a puzzle is a
SUSP, develop \emph{search} algorithms for searching for large SUSP,
and implement these algorithms in desktop and high performance
computing settings.  From the computational complexity perspective the
algorithms we develop to verify and search for SUSP are not efficient
as they run in exponential or doubly exponential time in the natural
parameters.  However, as the goal is to find a sufficiently large SUSP
which in turn produces a fast matrix multiplication algorithm, the
inefficiency of our algorithms does not directly impact the efficiency
of the matrix multiplication algorithms.  Rather, it indirectly
impacts the efficiency by limiting the search space of puzzles that we
can practically examine.

% Results

In addition to the various theoretical results, we have experimental
results that bound the size of the largest SUSP for small width
puzzles.  For small constant width the bounds are tight, though the
tightness of the results decreases as width increases.  Lower bounds
on size are witnessed by examples of SUSP we found via search and
constructions that compose SUSP of small width into SUSP of larger
width while maintaining the relative size of the SUSP.  Upper bounds
are determined computationally by evaluating admissible heuristics on
the initial levels of the puzzle search tree.  Although our current
experimental results do not beat Proposition 3.8 of \cite{cksu05} for
unbounded $k$, they do suggest there is considerable room for
improvement.

% Organization
\paragraph{Organization}
We begin with formal definitions and properties of puzzles and strong
uniquely solvable puzzles in \autoref{sec:prelim}.  In
\autoref{sec:verify} we discuss our algorithms for verifying that a
puzzle is a SUSP.  In \autoref{sec:heuristic} we describe fast,
but incomplete, heuristics for verifying SUSP.
\autoref{sec:search} explains our search algorithms.
\autoref{sec:results} discuss our implementation, experiments, and
the experimental results.


\section{Preliminaries}
\label{sec:prelim}

\newcommand\ordset[1]{\ensuremath{[#1]}}

We use $\ordset{n}$ to denote the set $\set{0,1,2,\ldots, n-1}$.  For
a set $Q$, $\Sym{Q}$ denotes the symmetric group on the elements of
$Q$.  \cite{cksu05} introduced the idea of a \emph{puzzle}.

\begin{definition}[Puzzle]
  For $s, k \in \Natural$, an $(s,k)$-\emph{puzzle} is a
  subset $P \sse U_k = \ordset{3}^k$ with $|P| = s$.
\end{definition}

We say that an $(s,k)$-puzzle has $s$ rows and $k$ columns.  The
columns are inherent ordered and indexed by $\ordset{k}$.  The rows are not
inherently ordered, however, it is often convienent to assume that the
rows are arbitrarily ordered and indexed by $\ordset{s}$.

\cite{cksu05} also establish a particular combinatorial property of
such puzzles that can derive groups that matrix multiplication can be
embedded into.  Such puzzles are called \emph{strong} uniquely
solvable puzzles.  However, to give some intuition we first explain a
simpler version of the property called \emph{uniquely solvable
  puzzles}.

\begin{definition}[Uniquely Solvable Puzzle (USP)]
  ~\\An $(s,k)$-puzzle $P$ is \emph{uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that at least two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
\end{definition}

Informally a puzzle is \textbf{not} uniquely solvable if each row of
the puzzle can be broken into zeros, ones, and twos pieces and then
the rows can be reassembled in a different way so that each new row is
a combination of a zeroes, a ones, and twos piece where there is
exactly element of $\ordset{3}$ for each column.  Observe that uniquely
solvable puzzles can have at most $2^k$ rows because each zeroes
piece, ones piece, and two piece must be unique, as otherwise the
duplicate pieces can be swapped making the puzzle not uniquely
solvable.  The definition of \emph{strong} uniquely solvable puzzle is
below, it is nearly the same except that it requires that there be a
collision on a column between exactly two pieces, not two or more
pieces like in the original definition.

\begin{definition}[Strong Uniquely Solvable Puzzle]
  ~\\
  An $(s,k)$-puzzle $P$ is \emph{strong uniquely solvable} if
  $\forall \pi_0, \pi_1, \pi_2 \in \Sym{P}:$
  \begin{enumerate}
  \item either $\pi_0 = \pi_1 = \pi_2$, or
  \item $\exists r \in P, \exists i \in \ordset{k}$ such that exactly two
    of the following hold:
    \begin{enumerate}
    \item $(\pi_0(r))_i = 0$,
    \item $(\pi_1(r))_i = 1$,
    \item $(\pi_2(r))_i = 2$.
    \end{enumerate}
  \end{enumerate}
  
\end{definition}

Observe that the properties of uniquely solvable and strong uniquely
solvable are invariant to the ordering of the rows or columns of a
puzzle.  This fact is used implicitly.  Also note that these
properties are invariant to maps between puzzles induced by
permutations from \Sym{\ordset{3}} on the puzzle cell elements.

Cohn et al.~ show the following connection between the existence of
strong uniquely solvable puzzles and upper bounds on the exponent of
matrix multiplication $\omega$.

\begin{lemma}[{\cite[Corollary 3.6]{cksu05}}]
  If there is a strong uniquely solvable $(s,k)$-puzzle,
  $$\omega \le \min_{m \ge 3, m \in \Natural} \frac{3 \log
    m}{\log(m-1)} - \frac{3 \log s!}{sk \log(m-1)}.$$
\end{lemma}

In the same article, the authors also demonstrate the existence of an
infinite family of strong uniquely solvable puzzles that achieves a
non-trivial bound on $\omega$.

\begin{lemma}[{\cite[Proposition 3.8]{cksu05}}]
  There is an infinite family of strong uniquely solvable puzzles that
  achieves $\omega < 2.48$.
\end{lemma}

Finally, they conjecture that strong uniquely solvable puzzles provide
a root to achieving quadratic time matrix multiplication.

\begin{conjecture}[{\cite{cksu05}}]
  There exists a family of strong uniquely solvable puzzles that
  implies $\omega = 2$.
\end{conjecture}

Unfortunately, this conjecture was recently shown to be false.

\begin{lemma}[\cite{bccgu16}]
  Strong uniquely solvable puzzles cannot show $\omega < 2 +
  \epsilon$, for some $\epsilon > 0$.
\end{lemma}

This result is a consequence of a recent breakthrough arithmetic
progressions in cap sets \cite{e16,clp16} combined with a conditional
result on the Erd\"{o}s-Szemeredi sunflower conjecture \cite{asu13}.
The results of \cite{bccgu16} do imply that Cohn and Umans' strong
uniquely solvable puzzle approach cannot achieve the ideal $\omega =
2$.  However, we are unaware of a concrete lower bound on $\epsilon$
implies by this result.  This means there is a still a substantial gap
in our understanding between what has been acheived by the refinements
of LeGall, Williams, and Stothers, and the impossibility of showing
$\omega = 2$ using the Cohn and Umans' approach.



\section{Verifying for Strong USPs}
\label{sec:verify}

\subsection{3DM to 3SAT}
\label{subsec:3sat}

\subsection{Heuristics}
\label{sec:heuristic}

Despite our efforts devise an exact algorithm for verifying strong
USPs, the performance of the final algorithm was not practical.  To
speed the algorithm up we considered a number of verification
heuristics that were fast to evaluate, but did not alway produce a
definitive answer.  The heuristics output YES, NO, or MAYBE to whether
a given puzzle $P$ was a strong USP.  We consider only Las Vegas
algorithms here, that is, algorithms whose output of YES or NO is
always correct.  Further, all the heuristics we consider are one-sided
in that they for all input they either return YES or MAYBE, or NO or
MAYBE.  To verify a puzzle $P$ we run a battery of fast heuristics and
return early if any of the heuristics produce a definitive YES or NO.
When all the heuristics result in MAYBE then run one of the slower
exact algorithms that were discussed in the previous section.  Most of
the heuristics we considered were deterministic, but a few were
randomized.  This is again in the Las Vegas sense: An output of YES or
NO is always correct, but as function of the input and internal
algorthmic randomness MAYBE can be also be output and can vary between
independent runs.  The heuristics have several different forms, but
all rely ultimately on structural properties of strong USP.

\subsubsection{Downward Closed}

The simplest heuristics we considered were based on the fact that
strong USP are downward closed, that is, if $P$ is a strong USP, then
so is every subpuzzle $P' \sse P$.  This leads to practical heuristic
that can determine that a puzzle is not a strong USP.

\begin{algorithm}
  \caption{: Downward-closed Heuristic}
  \label{alg:downward-closed}
\begin{algorithmic}[1]
  \Require{an $(s,k)$-puzzle $P$, and size $s' \le s$.}
  \Ensure{NO, if $P$ has a set of $s'$ rows that do not form a strong USP, and MAYBE otherwise.}
  \For{$P' \sse P, |P'| = s'$}
      \If{$P'$ is not a strong USP} \Return{NO.} \EndIf
  \EndFor{}
  \State{\Return{MAYBE}.}
\end{algorithmic}
\end{algorithm}

This algorithm runs in time $O(s^{s'} T_{Verify}(s', k))$ where
$T_{Verify}(s',k)$ is the running time for exactly verifying a
$(s',k)$-puzzle.  In practice we did not apply this heuristic for $s'$
larger than $3$, so the effective running time was $O(s^3 T(3,k))$,
which is polynomial in $s$ and $k$ using the verification algorithms
from the previous section which eliminate dependence on $k$ for
polynomial cost.  This heuristic can be made even more practical by
caching the results for puzzles of size $s'$, reducing the
verification time per iteration to constant in exchange for
$O(2^{s'k}T(s',k))$ time to precompute the values for all puzzles of
size $s'$.  There is also space overhead because the precomputed
results are being cached.  We also note that for a puzzle $P$ that is
a strong USP, the heuristic takes $\Theta(s^3 T(3,k))$ time without
cache or $\Theta(s^3)$ with caching.

Note that since our search algorithms typically start from a known
strong USP and tries to add rows, looking a subsets of a puzzle that
have already been verified is wasteful -- these are skipped over in
this setting.  From a practical point of view, running this heuristic
is free for small constant $s'$, as the exact verification algorithms
have a matching or higher polynomial running time.  Furthermore, since
the algorithm can return early, its expected running time on random
non-strong USPs is low.  There appeared to be dimenishing returns with
increasing $s'$ as it substantially increases precompute time and
storage while each stored value contributes relatively less to
verification as there are now many more values stored.

\subsubsection{Random Greedy}

This heuristic attempts to solve the 3D-Matching instance associated
with verifying a puzzle $P$ (discussed in \autoref{sec:3DM}).  The
heuristic proceeds iteratively, determining the layer of the 3DM
instance with the least edges and randomly selecting an edge in that
layer to put into the 3DM.  If the heuristic successfully contructs a
3DM it returns NO indicating that the input puzzle $P$ is not a strong
USP.  If the heuristic reaches point were prior commits have made the
matching infeasible, the heuristic starts again from scratch.  This
process is repeated some number of times before it gives up and
returns MAYBE.  In our practical implementation we use $s^3$
iterations because the time balances well with the other heuristics
and effectively reduced the number of instances requiring a full
verification.

\begin{algorithm}
  \caption{: Random Greedy Heuristic}
  \label{alg:random-greedy}
\begin{algorithmic}[1]
  \Require{an $(s,k)$-puzzle $P$, and iteration bound $t$.}
  \Ensure{NO, if a witness is found for $P$ not being a strong USP, and MAYBE otherwise.}
  \State{Construct 3DM instance $G : [s] \times [s] \times [s] \rightarrow \set{0,1}$ using $P$.}
  \For{$i = 1$ to $t$}
    \For{$j = 1$ to $s$}
      \State{$counts[j] =$ Number of edges incident vertex $j = \sum_{q,r} G(j,q,r)$.}
    \EndFor
    \State{Let $J,Q,R = \emptyset.$}
    \State{$m = 1$}
    \While{$m \le s$}
      \State{\texttt{// Select edge to add.}}
      \State{Select $j \in \condset{j \in \bar{J}}{counts[j] = \max_{q \in \bar{J}} counts[q]}$ uniformly at random.}
      \If{$counts[j] \le 0$} break. \EndIf
      \State{Select $(q,r) \in \condset{(q,r) \in \bar{Q} \times \bar{R}}{G(j,q,r) = 1}$ uniformly at random.}
      \State{\texttt{// Update edges counts.}}
      \For{$u = 1$ to $s$}
        \For{$v = 1$ to $s$}
          \If{$(u,v) \in \bar{Q} \times \bar{R}$ and $G(j,u,v) = 1$} $counts[j] = counts[j] - 1$. \EndIf
          \If{$(u,v) \in \bar{J} \times \bar{R}$ and $G(u,q,v) = 1$ and $u \neq j$} $counts[u] = counts[u] - 1$. \EndIf
          \If{$(u,v) \in \bar{J} \times \bar{Q}$ and $G(u,v,r) = 1$ and $u \neq j$ and $v \neq q$} $counts[u] = counts[u] - 1$. \EndIf 
        \EndFor
      \EndFor
      \State{$J = J \cup \set{j}$.}
      \State{$Q = Q \cup \set{q}$.}
      \State{$R = R \cup \set{r}$.}
      \State{$m = m + 1.$}
      \EndWhile
    \If {$m > s$} \Return{NO} \EndIf
  \EndFor
  \State{\Return{MAYBE}}
\end{algorithmic}
\end{algorithm}

The array $counts$ is used to store the number of edges $counts[j]$
that remain associated with vertex $j$ along the first coordinate.
Much of the algorithm is devoted to maintaining this invariant.  The
arrays $J,Q,R$ store the vertices along the three coordinates,
respectively, that have already been incorporated into the partial 3D
matching.  Like in our previous algorithms we do not store the
matching itself, only the vertices involved.  The break at Line 10
triggers when the partial 3D matching is a dead end and cannot be
extended into a full 3D matching.  The condition of Line 22 is true
when a full 3D matching has been constructed and causes the algorithm
to return that $P$ is not a strong USP.

The running time of this algorithm is $O(s^3 t + T_{3DM}(s,k))$, where
$T_{3DM}(s,k)$ is the time required to construct 3D matching
instances from $(s,k)$-puzzles.  This algorithm has the potential to
be considerably slower than the downward-closure heuristic, especially
when $t = s^3$.  However, the main loop can terminate early at Line 10
when it fails to extend the 3D matching this permits the expected time
to much less than the worst case.  For a puzzle $P$ that is a strong
USP, the heuristic takes the full $\Omega(s^3 t + T_{3DM}(s,k))$ time.  


\begin{comment}
\subsubsection{Random}

XXX - There's also a random reordering heuristic, but I don't remember
the justification for it.  It's more elaborate than the other, but
less motivated.
 
\subsubsection{Graph Automorphism}

A strong uniquely-solvable puzzle must also be a uniquely-solvable
puzzle.  Given a puzzle $P$ we can construct a graph $G_P$ such that
$G_P$ is rigid iff $P$ is a uniquely-solvable puzzle.

XXX - I don't think this idea worked out.  The code correctly
implemented the approach, but the approach was flawed.  Probably
remove this section or add to future work.

\end{comment}

\subsubsection{2D Matching}

The final heuristic we present is one-sided in the opposite direction
of the others, it may return YES or MAYBE.  In order for a hypergraph
$G = \langle [s] \times [s] \times [s], E\rangle$ to have a 3D
matching it must be the case that when any one of the three parts of
vertices of $G$ is projected away the resulting bipartite graph has a
perfect matching.  Thus we can witness that there is no 3D matching by
determining that one of three projected bipartite graphs $G|_1, G|_2,
G|_3$ does not have a perfect matching. 

\begin{algorithm}
  \caption{: 2D Matching Heuristic}
  \label{alg:2dm}
\begin{algorithmic}[1]
  \Require{an $(s,k)$-puzzle $P$.}
  \Ensure{YES, if $P$ is found to be strong USP, and MAYBE otherwise.}
  \State{Construct 3DM instance $G : [s] \times [s] \times [s] \rightarrow \set{0,1}$ using $P$.}
  \State{\texttt{// Construct projections.}}
  \State{Define projection $G|_1(b,c) = \vee_{a \in [s]} G(a,b,c)$.}
  \State{Define projection $G|_2(a,c) = \vee_{b \in [s]} G(a,b,c)$.}
  \State{Define projection $G|_3(a,b) = \vee_{c \in [s]} G(a,b,c)$.}

  \If{$G|_1, G|_2,$ and $G|_3$ have bipartite perfect matchings}
  \State{\Return{MAYBE.}}
  \Else
  \State{\Return{YES.}}
  \EndIf
\end{algorithmic}
\end{algorithm}

We can efficiently decide bipartite perfect matching using the
standard reduction to network flow and solve it using the
Ford-Faulkerson augmenting flow algorithm.  This approach yields an
algorithm that runs in time $O(s^3 + T_{3DM}(s,k))$, where
$T_{3DM}(s,k)$ is the time required to construct 3D matching instances
from $(s,k)$-puzzles.

In practice we found this heuristic not to be effective because the
projected $G|_i$ are typically dense graphs even if $G$ is not, and so
they are likely to have perfect matchings independently of whether $G$
has a 3D matching.







\section{Searching for Strong USPs}
\label{sec:search}

\section{Experimental Results}
\label{sec:results}

\subsection{Strong USPs Found}
\label{subsec:usps_found}

\begin{figure}
  \label{fig:examples}
  \begin{multicols}{4}
  (1,1):\\[.5ex]
  \begin{tabular}{|c|}
    \hline
    1 \\ \hline
  \end{tabular}\\[6ex]

  (2,2):\\[.5ex]
  \begin{tabular}{|c|c|}
    \hline
    1&3 \\ \hline
    2&1 \\ \hline
  \end{tabular}\\[16ex]

  (3,3):\\[.5ex]
  \begin{tabular}{|c|c|c|}
    \hline
    1&1&1 \\ \hline
    3&2&1 \\ \hline
    3&3&2 \\ \hline
    \end{tabular}\\[2ex]

  (5,4):\\[.5ex]
  \begin{tabular}{|c|c|c|c|}
    \hline
    3&1&3&2 \\ \hline
    1&2&3&2 \\ \hline
    1&1&1&3 \\ \hline 
    3&2&1&3 \\ \hline 
    3&3&2&3 \\ \hline
  \end{tabular}\\[10ex]

  (8,5):\\[.5ex]
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    3&3&3&1&1 \\ \hline
    1&1&2&2&1 \\ \hline
    2&1&3&3&2 \\ \hline
    3&2&2&2&3 \\ \hline
    2&1&2&1&3 \\ \hline
    2&2&3&1&2 \\ \hline
    3&2&3&2&1 \\ \hline
    3&1&2&1&1 \\ \hline
  \end{tabular}\\[16ex]
    
  (14,6):\\[.5ex]
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    2&3&3&1&1&1 \\ \hline
    2&1&1&2&1&1 \\ \hline
    3&3&1&2&1&1 \\\hline
    3&2&2&2&1&1 \\\hline
    2&3&1&1&2&1 \\\hline
    2&2&3&1&2&1 \\\hline
    3&3&1&3&2&1 \\\hline
    3&2&3&3&2&1 \\\hline
    2&1&1&3&1&2 \\\hline
    2&3&1&3&2&2 \\\hline
    3&1&1&1&1&3 \\\hline
    3&3&2&3&1&3 \\\hline
    3&3&2&1&2&3 \\\hline
    2&2&3&2&2&3 \\\hline
  \end{tabular}
  \end{multicols}
  \caption{Respresentative examples of the largest strong uniquely
    solvable $(s,k)$-puzzles found from width $k = 1$ to $6$.}
\end{figure}

\autoref{table:compare} summarizes our main results which are
improved bounds on the maximum size of strong uniquely solvable
puzzles and compares them to bounds from \cite{cksu05}.  XXX
\begin{table}
  \label{table:compare}
  \begin{center}
  \begin{tabular}{|c|r|r|r|r|}
    \hline
    & \multicolumn{2}{|c|}{[CKSU05]} & \multicolumn{2}{|c|}{This work} \\
    \hline
    $k$ & Maximum $s$ & $\omega^*$~ & Maximum $s$ & $\omega^*$~\\
    \hline
    1 & $s\le ~~~~1$ & & $1=s$ & $3.000$  \\
    2 & $s\le ~~~~3$ & & $2=s$ & $2.670$ \\
    3 & $3 \le s \le ~~~~6$ & $2.642$ & $3=s$ & $2.642$ \\
    4 & $s\le ~~12$ & & $5=s$ & $2.585$ \\
    5 & $s\le ~~24$ & & $8=s$ & $2.562$  \\
    6 & $10 \le s \le ~~45$ & $2.615$ &$14\le s$ & $2.521$\\
    7 & $s\le ~~86$ & & $21\le s$ & $2.531$ \\
    8 & $s\le 162$ & & $30\le s$ & $2.547$ \\
    9 & $36 \le s \le 307$ & $2.592$ &$42\le s$ & $2.563$  \\
    \hline
  \end{tabular}
  \end{center}
  \caption{Comparison of bounds on maximum size of strong uniquely
    solvable $(s,k)$-puzzles with \cite{cksu05}.  $\omega^*$ is the
    $\omega$ in the limit of composing puzzles of these dimensions via
    direct product.}
\end{table}
  
\subsection{Algorithm Performance}
\label{subsec:performance}

\section{Conclusions}
\label{sec:conclusion}



\bibliographystyle{customurlbst/alphaurlpp} \bibliography{references}

\appendix


\end{document}
